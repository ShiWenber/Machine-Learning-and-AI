{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pytorch\n",
    "\n",
    "使用pytorch实现的两层前向传播神经网络\n",
    "\n",
    "只有隐层需要激活函数，输出层不需要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 128)\n",
      "(500,)\n",
      "(100, 128)\n",
      "(100,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x214f7490ed0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from neural_network import *\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "\n",
    "\n",
    "data_small = load_data_small()\n",
    "data_medium = load_data_medium()\n",
    "data_large = load_data_large()\n",
    "print(data_small[0].shape)\n",
    "print(data_small[1].shape)\n",
    "print(data_small[2].shape)\n",
    "print(data_small[3].shape)\n",
    "# 每个数据集的组织形式都是data[0]为X_train，data[1]为y_train\n",
    "data_large[0]\n",
    "type(type(data_large[0]))\n",
    "data_large[0].astype(np.uint8)\n",
    "data_large[0].shape\n",
    "data_large[0][0].shape\n",
    "# 将一行转化为16*8的矩阵\n",
    "data_large[0][0].reshape(8,16).shape\n",
    "# 用plt输出\n",
    "plt.imshow(data_large[0][0].reshape(16,8),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num2str(num):\n",
    "    \"\"\"\n",
    "    Label 0 corresponds to “a,” 1 to “e,” 2 to “g,” 3 to “i,” 4 to “l,” 5 to \n",
    "    “n,” 6 to “o,” 7 to “r,” 8 to “t,” and 9 to “u.”\n",
    "\n",
    "    Args:\n",
    "        num (str): 标签含义\n",
    "    \"\"\"\n",
    "    if num == 0:\n",
    "        return 'a'\n",
    "    elif num == 1:\n",
    "        return 'e'\n",
    "    elif num == 2:\n",
    "        return 'g'\n",
    "    elif num == 3:\n",
    "        return 'i'\n",
    "    elif num == 4:\n",
    "        return 'l'\n",
    "    elif num == 5:\n",
    "        return 'n'\n",
    "    elif num == 6:\n",
    "        return 'o'\n",
    "    elif num == 7:\n",
    "        return 'r'\n",
    "    elif num == 8:\n",
    "        return 't'\n",
    "    elif num == 9:\n",
    "        return 'u'\n",
    "    \n",
    "        \n",
    "\n",
    "\n",
    "label_num = data_small[1]\n",
    "# 使用map方法提高效率\n",
    "label_num = list(map(num2str, label_num))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x300 with 30 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 各随机抽取10张进行展示\n",
    "# 随机生成10个下标\n",
    "index_idx = 0\n",
    "index = np.random.randint(0, data_small[0].shape[0], 10)\n",
    "assert len(index) == 10\n",
    "print(index[0])\n",
    "fig, ax = plt.subplots(3, 10, figsize=(10, 3))\n",
    "label_str_small = list(map(num2str, data_small[1]))\n",
    "label_str_medium = list(map(num2str, data_medium[1]))\n",
    "label_str_large = list(map(num2str, data_large[1]))\n",
    "for i in range(10):\n",
    "    ax[0, i].imshow(data_small[0][index[index_idx]].reshape(16, 8), cmap='gray')\n",
    "    ax[1, i].imshow(data_medium[0][index[index_idx]].reshape(16, 8), cmap='gray')\n",
    "    ax[2, i].imshow(data_large[0][index[index_idx]].reshape(16,8), cmap='gray')\n",
    "    index_idx += 1\n",
    "    ax[0, i].axis('off')\n",
    "    ax[0, i].set_title(label_str_small[index[i]])\n",
    "    ax[1, i].axis('off')\n",
    "    ax[1, i].set_title(label_str_medium[index[i]])\n",
    "    ax[2, i].axis('off')\n",
    "    ax[2, i].set_title(label_str_large[index[i]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def one_hot(y, num_class):\n",
    "    return np.eye(num_class)[y]\n",
    "label_train_small = one_hot(data_small[1], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    \"\"\"实现一个单隐层的前向神经网络模型\n",
    "    fc->sigmoid->fc->sigmoid\n",
    "    \"\"\"\n",
    "    def __init__(self, in_features, hidden_features, out_features):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features, hidden_features) # 输入层到隐层， fc表示全连接层，输入特征数为in_features，输出特征数为hidden_features\n",
    "        self.fc2 = nn.Linear(hidden_features, out_features) # 隐层到输出层，输入特征数为hidden_features，输出特征数为out_features\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"fc->sigmoid->sigmoid\n",
    "        \"\"\"\n",
    "        x = self.fc1(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 9, 3, 7, 8, 1, 4, 4, 5, 3, 6, 4, 3, 7, 9, 7, 0, 7, 9, 9, 7, 5,\n",
       "       2, 0, 5, 3, 8, 6, 5, 7, 6, 3, 9, 1, 6, 9, 4, 9, 6, 6, 4, 3, 6, 9,\n",
       "       0, 5, 2, 1, 2, 3, 8, 0, 3, 8, 9, 4, 2, 0, 7, 1, 2, 5, 8, 7, 2, 4,\n",
       "       5, 2, 1, 7, 5, 5, 0, 2, 9, 9, 0, 8, 9, 4, 4, 7, 7, 3, 8, 8, 7, 1,\n",
       "       1, 2, 1, 5, 4, 0, 8, 1, 8, 9, 5, 7, 1, 0, 2, 7, 9, 5, 0, 6, 9, 3,\n",
       "       0, 8, 8, 1, 0, 8, 5, 2, 2, 5, 6, 5, 6, 3, 2, 8, 3, 7, 3, 8, 0, 4,\n",
       "       9, 8, 6, 9, 0, 3, 3, 5, 3, 2, 4, 7, 2, 9, 4, 9, 0, 2, 8, 1, 2, 9,\n",
       "       5, 1, 5, 1, 8, 1, 1, 9, 3, 4, 4, 2, 5, 2, 5, 5, 7, 2, 1, 9, 6, 3,\n",
       "       5, 0, 1, 7, 3, 5, 6, 8, 1, 3, 1, 4, 1, 3, 8, 2, 5, 1, 5, 7, 6, 9,\n",
       "       8, 8, 9, 3, 1, 2, 7, 8, 4, 5, 1, 6, 2, 5, 6, 9, 6, 9, 8, 8, 9, 8,\n",
       "       1, 0, 5, 9, 5, 6, 0, 2, 3, 0, 1, 8, 3, 2, 1, 9, 9, 4, 7, 3, 4, 5,\n",
       "       8, 3, 9, 9, 4, 2, 4, 1, 2, 3, 5, 5, 9, 6, 0, 0, 5, 5, 3, 0, 9, 4,\n",
       "       1, 7, 4, 6, 4, 8, 3, 2, 0, 5, 1, 0, 3, 6, 0, 2, 8, 7, 7, 8, 0, 3,\n",
       "       9, 0, 2, 7, 7, 4, 6, 9, 2, 7, 0, 1, 3, 3, 8, 6, 9, 6, 5, 9, 7, 8,\n",
       "       2, 8, 3, 6, 7, 6, 8, 9, 4, 1, 8, 5, 9, 6, 2, 9, 4, 2, 4, 1, 8, 6,\n",
       "       3, 5, 4, 6, 2, 9, 0, 3, 0, 1, 1, 8, 4, 3, 6, 0, 7, 8, 5, 5, 2, 5,\n",
       "       0, 7, 6, 4, 7, 0, 9, 7, 4, 6, 4, 2, 9, 9, 7, 8, 4, 4, 1, 6, 9, 0,\n",
       "       6, 5, 2, 0, 7, 9, 9, 7, 5, 7, 7, 5, 0, 2, 3, 7, 4, 6, 0, 1, 1, 7,\n",
       "       0, 3, 6, 2, 5, 3, 1, 1, 3, 7, 5, 7, 1, 5, 2, 8, 3, 4, 7, 6, 3, 5,\n",
       "       3, 7, 8, 1, 7, 4, 3, 0, 0, 3, 7, 8, 4, 6, 1, 6, 4, 2, 3, 2, 1, 6,\n",
       "       4, 3, 0, 7, 6, 2, 4, 4, 0, 4, 0, 1, 7, 1, 4, 2, 9, 0, 8, 2, 1, 4,\n",
       "       0, 0, 8, 6, 5, 0, 6, 1, 4, 2, 7, 4, 4, 9, 3, 7, 5, 8, 8, 2, 2, 6,\n",
       "       8, 1, 8, 0, 4, 8, 6, 1, 6, 0, 6, 3, 0, 2, 6, 6])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = nn.CrossEntropyLoss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.optim.sgd.SGD'>\n",
      "Epoch 1, Loss: 0.14782725620269777, Accuracy: 0.1\n",
      "Epoch 2, Loss: 0.14756586599349975, Accuracy: 0.11\n",
      "Epoch 3, Loss: 0.14737917995452882, Accuracy: 0.1\n",
      "Epoch 4, Loss: 0.14721911430358886, Accuracy: 0.1\n",
      "Epoch 5, Loss: 0.14706902265548705, Accuracy: 0.1\n",
      "Epoch 6, Loss: 0.14692030715942384, Accuracy: 0.1\n",
      "Epoch 7, Loss: 0.14676799488067627, Accuracy: 0.1\n",
      "Epoch 8, Loss: 0.14660877561569213, Accuracy: 0.1\n",
      "Epoch 9, Loss: 0.14644006681442262, Accuracy: 0.1\n",
      "Epoch 10, Loss: 0.14625954294204713, Accuracy: 0.11\n",
      "Epoch 11, Loss: 0.1460649290084839, Accuracy: 0.11\n",
      "Epoch 12, Loss: 0.14585389280319214, Accuracy: 0.13\n",
      "Epoch 13, Loss: 0.14562402629852295, Accuracy: 0.15\n",
      "Epoch 14, Loss: 0.14537283658981323, Accuracy: 0.19\n",
      "Epoch 15, Loss: 0.14509779119491578, Accuracy: 0.25\n",
      "Epoch 16, Loss: 0.14479634761810303, Accuracy: 0.29\n",
      "Epoch 17, Loss: 0.14446603345870973, Accuracy: 0.31\n",
      "Epoch 18, Loss: 0.1441045551300049, Accuracy: 0.33\n",
      "Epoch 19, Loss: 0.14370991611480713, Accuracy: 0.32\n",
      "Epoch 20, Loss: 0.1432805643081665, Accuracy: 0.32\n",
      "Epoch 21, Loss: 0.14281558084487916, Accuracy: 0.33\n",
      "Epoch 22, Loss: 0.14231481742858887, Accuracy: 0.35\n",
      "Epoch 23, Loss: 0.14177910566329957, Accuracy: 0.35\n",
      "Epoch 24, Loss: 0.14121030616760255, Accuracy: 0.38\n",
      "Epoch 25, Loss: 0.14061141395568846, Accuracy: 0.39\n",
      "Epoch 26, Loss: 0.1399864592552185, Accuracy: 0.39\n",
      "Epoch 27, Loss: 0.13934037923812867, Accuracy: 0.4\n",
      "Epoch 28, Loss: 0.13867875051498413, Accuracy: 0.42\n",
      "Epoch 29, Loss: 0.13800746488571167, Accuracy: 0.44\n",
      "Epoch 30, Loss: 0.1373324294090271, Accuracy: 0.44\n",
      "Epoch 31, Loss: 0.13665919876098634, Accuracy: 0.46\n",
      "Epoch 32, Loss: 0.13599275732040406, Accuracy: 0.48\n",
      "Epoch 33, Loss: 0.13533736085891723, Accuracy: 0.49\n",
      "Epoch 34, Loss: 0.13469640445709227, Accuracy: 0.49\n",
      "Epoch 35, Loss: 0.13407248258590698, Accuracy: 0.51\n",
      "Epoch 36, Loss: 0.13346739339828492, Accuracy: 0.51\n",
      "Epoch 37, Loss: 0.1328822431564331, Accuracy: 0.53\n",
      "Epoch 38, Loss: 0.13231756353378296, Accuracy: 0.54\n",
      "Epoch 39, Loss: 0.13177338409423828, Accuracy: 0.55\n",
      "Epoch 40, Loss: 0.13124937129020692, Accuracy: 0.55\n",
      "Epoch 41, Loss: 0.13074489593505859, Accuracy: 0.53\n",
      "Epoch 42, Loss: 0.13025913453102111, Accuracy: 0.54\n",
      "Epoch 43, Loss: 0.12979110670089722, Accuracy: 0.53\n",
      "Epoch 44, Loss: 0.1293397641181946, Accuracy: 0.54\n",
      "Epoch 45, Loss: 0.12890400958061218, Accuracy: 0.52\n",
      "Epoch 46, Loss: 0.12848274493217468, Accuracy: 0.51\n",
      "Epoch 47, Loss: 0.12807489228248597, Accuracy: 0.5\n",
      "Epoch 48, Loss: 0.12767941284179687, Accuracy: 0.48\n",
      "Epoch 49, Loss: 0.12729533004760743, Accuracy: 0.47\n",
      "Epoch 50, Loss: 0.1269217267036438, Accuracy: 0.47\n",
      "Epoch 51, Loss: 0.12655776619911194, Accuracy: 0.47\n",
      "Epoch 52, Loss: 0.12620267534255983, Accuracy: 0.47\n",
      "Epoch 53, Loss: 0.12585576605796814, Accuracy: 0.47\n",
      "Epoch 54, Loss: 0.12551642751693726, Accuracy: 0.48\n",
      "Epoch 55, Loss: 0.1251841082572937, Accuracy: 0.48\n",
      "Epoch 56, Loss: 0.12485833692550659, Accuracy: 0.47\n",
      "Epoch 57, Loss: 0.12453869795799255, Accuracy: 0.47\n",
      "Epoch 58, Loss: 0.124224839925766, Accuracy: 0.47\n",
      "Epoch 59, Loss: 0.12391646242141724, Accuracy: 0.47\n",
      "Epoch 60, Loss: 0.12361331677436829, Accuracy: 0.47\n",
      "Epoch 61, Loss: 0.12331518816947937, Accuracy: 0.47\n",
      "Epoch 62, Loss: 0.12302191376686096, Accuracy: 0.47\n",
      "Epoch 63, Loss: 0.1227333505153656, Accuracy: 0.45\n",
      "Epoch 64, Loss: 0.12244938564300537, Accuracy: 0.45\n",
      "Epoch 65, Loss: 0.12216993570327758, Accuracy: 0.44\n",
      "Epoch 66, Loss: 0.12189492774009704, Accuracy: 0.45\n",
      "Epoch 67, Loss: 0.1216243052482605, Accuracy: 0.45\n",
      "Epoch 68, Loss: 0.1213580207824707, Accuracy: 0.45\n",
      "Epoch 69, Loss: 0.12109604144096374, Accuracy: 0.46\n",
      "Epoch 70, Loss: 0.12083833169937133, Accuracy: 0.46\n",
      "Epoch 71, Loss: 0.12058486104011536, Accuracy: 0.46\n",
      "Epoch 72, Loss: 0.1203356032371521, Accuracy: 0.46\n",
      "Epoch 73, Loss: 0.12009052515029907, Accuracy: 0.46\n",
      "Epoch 74, Loss: 0.11984959530830383, Accuracy: 0.46\n",
      "Epoch 75, Loss: 0.1196127848625183, Accuracy: 0.47\n",
      "Epoch 76, Loss: 0.11938005042076111, Accuracy: 0.47\n",
      "Epoch 77, Loss: 0.11915135812759399, Accuracy: 0.48\n",
      "Epoch 78, Loss: 0.11892666006088257, Accuracy: 0.48\n",
      "Epoch 79, Loss: 0.11870591259002686, Accuracy: 0.48\n",
      "Epoch 80, Loss: 0.11848906874656677, Accuracy: 0.48\n",
      "Epoch 81, Loss: 0.11827607178688049, Accuracy: 0.47\n",
      "Epoch 82, Loss: 0.11806686782836914, Accuracy: 0.47\n",
      "Epoch 83, Loss: 0.11786140561103821, Accuracy: 0.47\n",
      "Epoch 84, Loss: 0.11765961718559265, Accuracy: 0.47\n",
      "Epoch 85, Loss: 0.11746145224571228, Accuracy: 0.47\n",
      "Epoch 86, Loss: 0.11726684498786927, Accuracy: 0.48\n",
      "Epoch 87, Loss: 0.11707573175430298, Accuracy: 0.48\n",
      "Epoch 88, Loss: 0.11688805389404297, Accuracy: 0.47\n",
      "Epoch 89, Loss: 0.11670374536514282, Accuracy: 0.47\n",
      "Epoch 90, Loss: 0.1165227484703064, Accuracy: 0.48\n",
      "Epoch 91, Loss: 0.11634499621391296, Accuracy: 0.48\n",
      "Epoch 92, Loss: 0.11617042899131774, Accuracy: 0.48\n",
      "Epoch 93, Loss: 0.11599898552894593, Accuracy: 0.48\n",
      "Epoch 94, Loss: 0.11583060503005982, Accuracy: 0.48\n",
      "Epoch 95, Loss: 0.11566522431373596, Accuracy: 0.48\n",
      "Epoch 96, Loss: 0.11550278472900391, Accuracy: 0.48\n",
      "Epoch 97, Loss: 0.11534323072433472, Accuracy: 0.49\n",
      "Epoch 98, Loss: 0.11518650245666504, Accuracy: 0.5\n",
      "Epoch 99, Loss: 0.11503254318237305, Accuracy: 0.5\n",
      "Epoch 100, Loss: 0.11488129830360412, Accuracy: 0.5\n",
      "Epoch 101, Loss: 0.11473271179199218, Accuracy: 0.5\n",
      "Epoch 102, Loss: 0.11458672738075257, Accuracy: 0.5\n",
      "Epoch 103, Loss: 0.1144432897567749, Accuracy: 0.5\n",
      "Epoch 104, Loss: 0.11430234837532044, Accuracy: 0.5\n",
      "Epoch 105, Loss: 0.11416385269165039, Accuracy: 0.5\n",
      "Epoch 106, Loss: 0.11402774786949157, Accuracy: 0.5\n",
      "Epoch 107, Loss: 0.11389398384094239, Accuracy: 0.5\n",
      "Epoch 108, Loss: 0.11376251292228699, Accuracy: 0.5\n",
      "Epoch 109, Loss: 0.11363328051567077, Accuracy: 0.5\n",
      "Epoch 110, Loss: 0.11350624036788941, Accuracy: 0.5\n",
      "Epoch 111, Loss: 0.11338134360313415, Accuracy: 0.5\n",
      "Epoch 112, Loss: 0.11325854516029357, Accuracy: 0.5\n",
      "Epoch 113, Loss: 0.11313779592514038, Accuracy: 0.5\n",
      "Epoch 114, Loss: 0.11301904892921448, Accuracy: 0.5\n",
      "Epoch 115, Loss: 0.11290226078033447, Accuracy: 0.5\n",
      "Epoch 116, Loss: 0.11278738927841186, Accuracy: 0.5\n",
      "Epoch 117, Loss: 0.11267438101768494, Accuracy: 0.5\n",
      "Epoch 118, Loss: 0.11256320524215699, Accuracy: 0.5\n",
      "Epoch 119, Loss: 0.11245381426811218, Accuracy: 0.5\n",
      "Epoch 120, Loss: 0.11234616661071778, Accuracy: 0.5\n",
      "Epoch 121, Loss: 0.11224022150039673, Accuracy: 0.5\n",
      "Epoch 122, Loss: 0.11213594198226928, Accuracy: 0.5\n",
      "Epoch 123, Loss: 0.11203328728675842, Accuracy: 0.5\n",
      "Epoch 124, Loss: 0.11193221926689148, Accuracy: 0.5\n",
      "Epoch 125, Loss: 0.11183270454406738, Accuracy: 0.5\n",
      "Epoch 126, Loss: 0.11173470091819764, Accuracy: 0.5\n",
      "Epoch 127, Loss: 0.11163817691802978, Accuracy: 0.5\n",
      "Epoch 128, Loss: 0.11154309630393983, Accuracy: 0.5\n",
      "Epoch 129, Loss: 0.11144942831993103, Accuracy: 0.5\n",
      "Epoch 130, Loss: 0.11135713648796082, Accuracy: 0.5\n",
      "Epoch 131, Loss: 0.11126619172096253, Accuracy: 0.5\n",
      "Epoch 132, Loss: 0.11117656326293945, Accuracy: 0.51\n",
      "Epoch 133, Loss: 0.11108821439743043, Accuracy: 0.51\n",
      "Epoch 134, Loss: 0.11100112318992615, Accuracy: 0.51\n",
      "Epoch 135, Loss: 0.11091525840759277, Accuracy: 0.51\n",
      "Epoch 136, Loss: 0.11083059191703797, Accuracy: 0.51\n",
      "Epoch 137, Loss: 0.1107470920085907, Accuracy: 0.51\n",
      "Epoch 138, Loss: 0.11066473507881165, Accuracy: 0.51\n",
      "Epoch 139, Loss: 0.1105834972858429, Accuracy: 0.51\n",
      "Epoch 140, Loss: 0.11050335121154785, Accuracy: 0.51\n",
      "Epoch 141, Loss: 0.11042427277565002, Accuracy: 0.51\n",
      "Epoch 142, Loss: 0.11034623670578003, Accuracy: 0.51\n",
      "Epoch 143, Loss: 0.11026922178268432, Accuracy: 0.52\n",
      "Epoch 144, Loss: 0.11019320106506347, Accuracy: 0.52\n",
      "Epoch 145, Loss: 0.11011815881729126, Accuracy: 0.52\n",
      "Epoch 146, Loss: 0.11004406690597535, Accuracy: 0.52\n",
      "Epoch 147, Loss: 0.1099709084033966, Accuracy: 0.52\n",
      "Epoch 148, Loss: 0.10989866495132446, Accuracy: 0.52\n",
      "Epoch 149, Loss: 0.10982731246948242, Accuracy: 0.52\n",
      "Epoch 150, Loss: 0.10975683164596557, Accuracy: 0.52\n",
      "Epoch 151, Loss: 0.10968720579147338, Accuracy: 0.52\n",
      "Epoch 152, Loss: 0.1096184184551239, Accuracy: 0.52\n",
      "Epoch 153, Loss: 0.10955044627189636, Accuracy: 0.52\n",
      "Epoch 154, Loss: 0.10948327779769898, Accuracy: 0.52\n",
      "Epoch 155, Loss: 0.10941689133644104, Accuracy: 0.52\n",
      "Epoch 156, Loss: 0.10935127687454224, Accuracy: 0.52\n",
      "Epoch 157, Loss: 0.10928641533851624, Accuracy: 0.52\n",
      "Epoch 158, Loss: 0.10922228837013245, Accuracy: 0.52\n",
      "Epoch 159, Loss: 0.10915888738632203, Accuracy: 0.52\n",
      "Epoch 160, Loss: 0.10909619212150573, Accuracy: 0.52\n",
      "Epoch 161, Loss: 0.10903419208526612, Accuracy: 0.52\n",
      "Epoch 162, Loss: 0.10897287154197693, Accuracy: 0.52\n",
      "Epoch 163, Loss: 0.10891222047805786, Accuracy: 0.52\n",
      "Epoch 164, Loss: 0.10885222172737122, Accuracy: 0.52\n",
      "Epoch 165, Loss: 0.10879286432266236, Accuracy: 0.52\n",
      "Epoch 166, Loss: 0.10873413801193238, Accuracy: 0.52\n",
      "Epoch 167, Loss: 0.10867603135108948, Accuracy: 0.52\n",
      "Epoch 168, Loss: 0.10861853003501892, Accuracy: 0.52\n",
      "Epoch 169, Loss: 0.10856162643432617, Accuracy: 0.52\n",
      "Epoch 170, Loss: 0.10850530171394349, Accuracy: 0.52\n",
      "Epoch 171, Loss: 0.10844955563545228, Accuracy: 0.52\n",
      "Epoch 172, Loss: 0.10839437127113342, Accuracy: 0.52\n",
      "Epoch 173, Loss: 0.10833974266052246, Accuracy: 0.52\n",
      "Epoch 174, Loss: 0.10828565645217895, Accuracy: 0.52\n",
      "Epoch 175, Loss: 0.10823210716247558, Accuracy: 0.52\n",
      "Epoch 176, Loss: 0.10817908120155334, Accuracy: 0.52\n",
      "Epoch 177, Loss: 0.10812657403945923, Accuracy: 0.52\n",
      "Epoch 178, Loss: 0.10807457447052002, Accuracy: 0.52\n",
      "Epoch 179, Loss: 0.10802307510375976, Accuracy: 0.52\n",
      "Epoch 180, Loss: 0.10797206735610962, Accuracy: 0.53\n",
      "Epoch 181, Loss: 0.10792154407501221, Accuracy: 0.53\n",
      "Epoch 182, Loss: 0.10787149286270141, Accuracy: 0.53\n",
      "Epoch 183, Loss: 0.1078219141960144, Accuracy: 0.53\n",
      "Epoch 184, Loss: 0.10777279162406922, Accuracy: 0.53\n",
      "Epoch 185, Loss: 0.10772412800788879, Accuracy: 0.53\n",
      "Epoch 186, Loss: 0.10767590737342835, Accuracy: 0.53\n",
      "Epoch 187, Loss: 0.10762812685966491, Accuracy: 0.53\n",
      "Epoch 188, Loss: 0.1075807797908783, Accuracy: 0.53\n",
      "Epoch 189, Loss: 0.10753385853767396, Accuracy: 0.54\n",
      "Epoch 190, Loss: 0.1074873583316803, Accuracy: 0.54\n",
      "Epoch 191, Loss: 0.10744126987457275, Accuracy: 0.53\n",
      "Epoch 192, Loss: 0.10739558935165405, Accuracy: 0.53\n",
      "Epoch 193, Loss: 0.10735030913352966, Accuracy: 0.53\n",
      "Epoch 194, Loss: 0.10730542635917664, Accuracy: 0.53\n",
      "Epoch 195, Loss: 0.1072609326839447, Accuracy: 0.53\n",
      "Epoch 196, Loss: 0.10721682238578796, Accuracy: 0.53\n",
      "Epoch 197, Loss: 0.10717308974266052, Accuracy: 0.53\n",
      "Epoch 198, Loss: 0.10712973141670228, Accuracy: 0.53\n",
      "Epoch 199, Loss: 0.10708673977851868, Accuracy: 0.53\n",
      "Epoch 200, Loss: 0.10704411339759827, Accuracy: 0.53\n",
      "Epoch 201, Loss: 0.10700183963775635, Accuracy: 0.53\n",
      "Epoch 202, Loss: 0.10695992112159729, Accuracy: 0.53\n",
      "Epoch 203, Loss: 0.10691835045814514, Accuracy: 0.53\n",
      "Epoch 204, Loss: 0.10687712073326111, Accuracy: 0.53\n",
      "Epoch 205, Loss: 0.1068362283706665, Accuracy: 0.53\n",
      "Epoch 206, Loss: 0.1067956690788269, Accuracy: 0.54\n",
      "Epoch 207, Loss: 0.10675543785095215, Accuracy: 0.54\n",
      "Epoch 208, Loss: 0.1067155327796936, Accuracy: 0.54\n",
      "Epoch 209, Loss: 0.10667594695091248, Accuracy: 0.54\n",
      "Epoch 210, Loss: 0.10663667297363282, Accuracy: 0.54\n",
      "Epoch 211, Loss: 0.10659771299362182, Accuracy: 0.54\n",
      "Epoch 212, Loss: 0.10655905652046203, Accuracy: 0.53\n",
      "Epoch 213, Loss: 0.1065207040309906, Accuracy: 0.53\n",
      "Epoch 214, Loss: 0.10648265123367309, Accuracy: 0.53\n",
      "Epoch 215, Loss: 0.10644488763809204, Accuracy: 0.53\n",
      "Epoch 216, Loss: 0.10640741991996765, Accuracy: 0.53\n",
      "Epoch 217, Loss: 0.10637023639678955, Accuracy: 0.53\n",
      "Epoch 218, Loss: 0.10633333468437195, Accuracy: 0.53\n",
      "Epoch 219, Loss: 0.1062967095375061, Accuracy: 0.53\n",
      "Epoch 220, Loss: 0.10626036190986633, Accuracy: 0.53\n",
      "Epoch 221, Loss: 0.10622428607940673, Accuracy: 0.54\n",
      "Epoch 222, Loss: 0.10618847608566284, Accuracy: 0.54\n",
      "Epoch 223, Loss: 0.10615293049812317, Accuracy: 0.54\n",
      "Epoch 224, Loss: 0.10611764693260192, Accuracy: 0.54\n",
      "Epoch 225, Loss: 0.10608261823654175, Accuracy: 0.54\n",
      "Epoch 226, Loss: 0.10604784417152405, Accuracy: 0.54\n",
      "Epoch 227, Loss: 0.10601332020759582, Accuracy: 0.54\n",
      "Epoch 228, Loss: 0.10597904372215271, Accuracy: 0.54\n",
      "Epoch 229, Loss: 0.1059450101852417, Accuracy: 0.54\n",
      "Epoch 230, Loss: 0.10591121768951416, Accuracy: 0.54\n",
      "Epoch 231, Loss: 0.10587766027450561, Accuracy: 0.54\n",
      "Epoch 232, Loss: 0.10584433937072754, Accuracy: 0.54\n",
      "Epoch 233, Loss: 0.10581124806404114, Accuracy: 0.54\n",
      "Epoch 234, Loss: 0.10577838587760925, Accuracy: 0.54\n",
      "Epoch 235, Loss: 0.10574574780464173, Accuracy: 0.54\n",
      "Epoch 236, Loss: 0.10571333026885986, Accuracy: 0.54\n",
      "Epoch 237, Loss: 0.10568113207817077, Accuracy: 0.54\n",
      "Epoch 238, Loss: 0.10564915180206298, Accuracy: 0.54\n",
      "Epoch 239, Loss: 0.10561738348007202, Accuracy: 0.54\n",
      "Epoch 240, Loss: 0.10558582592010499, Accuracy: 0.54\n",
      "Epoch 241, Loss: 0.10555447363853454, Accuracy: 0.54\n",
      "Epoch 242, Loss: 0.1055233302116394, Accuracy: 0.54\n",
      "Epoch 243, Loss: 0.10549238705635071, Accuracy: 0.54\n",
      "Epoch 244, Loss: 0.10546164178848266, Accuracy: 0.55\n",
      "Epoch 245, Loss: 0.10543109655380249, Accuracy: 0.55\n",
      "Epoch 246, Loss: 0.1054007430076599, Accuracy: 0.55\n",
      "Epoch 247, Loss: 0.10537058019638061, Accuracy: 0.55\n",
      "Epoch 248, Loss: 0.10534060764312744, Accuracy: 0.55\n",
      "Epoch 249, Loss: 0.10531082129478454, Accuracy: 0.55\n",
      "Epoch 250, Loss: 0.10528121852874756, Accuracy: 0.55\n",
      "Epoch 251, Loss: 0.10525179815292358, Accuracy: 0.55\n",
      "Epoch 252, Loss: 0.10522255706787109, Accuracy: 0.55\n",
      "Epoch 253, Loss: 0.10519349265098572, Accuracy: 0.55\n",
      "Epoch 254, Loss: 0.1051646032333374, Accuracy: 0.55\n",
      "Epoch 255, Loss: 0.10513588643074036, Accuracy: 0.55\n",
      "Epoch 256, Loss: 0.10510733604431152, Accuracy: 0.55\n",
      "Epoch 257, Loss: 0.10507895469665528, Accuracy: 0.55\n",
      "Epoch 258, Loss: 0.1050507390499115, Accuracy: 0.55\n",
      "Epoch 259, Loss: 0.10502268576622009, Accuracy: 0.55\n",
      "Epoch 260, Loss: 0.1049947955608368, Accuracy: 0.55\n",
      "Epoch 261, Loss: 0.10496706318855285, Accuracy: 0.55\n",
      "Epoch 262, Loss: 0.1049394850730896, Accuracy: 0.56\n",
      "Epoch 263, Loss: 0.10491206407546998, Accuracy: 0.56\n",
      "Epoch 264, Loss: 0.10488479471206665, Accuracy: 0.56\n",
      "Epoch 265, Loss: 0.10485767507553101, Accuracy: 0.56\n",
      "Epoch 266, Loss: 0.10483070421218872, Accuracy: 0.56\n",
      "Epoch 267, Loss: 0.10480388116836548, Accuracy: 0.56\n",
      "Epoch 268, Loss: 0.10477720141410828, Accuracy: 0.56\n",
      "Epoch 269, Loss: 0.10475066208839416, Accuracy: 0.56\n",
      "Epoch 270, Loss: 0.10472426629066467, Accuracy: 0.57\n",
      "Epoch 271, Loss: 0.10469800710678101, Accuracy: 0.56\n",
      "Epoch 272, Loss: 0.10467188692092895, Accuracy: 0.56\n",
      "Epoch 273, Loss: 0.10464590239524842, Accuracy: 0.56\n",
      "Epoch 274, Loss: 0.10462005019187927, Accuracy: 0.56\n",
      "Epoch 275, Loss: 0.10459432744979859, Accuracy: 0.56\n",
      "Epoch 276, Loss: 0.10456873750686646, Accuracy: 0.56\n",
      "Epoch 277, Loss: 0.1045432744026184, Accuracy: 0.56\n",
      "Epoch 278, Loss: 0.10451793789863587, Accuracy: 0.56\n",
      "Epoch 279, Loss: 0.10449272656440735, Accuracy: 0.56\n",
      "Epoch 280, Loss: 0.1044676411151886, Accuracy: 0.56\n",
      "Epoch 281, Loss: 0.10444267296791077, Accuracy: 0.56\n",
      "Epoch 282, Loss: 0.10441782903671265, Accuracy: 0.56\n",
      "Epoch 283, Loss: 0.10439310121536255, Accuracy: 0.56\n",
      "Epoch 284, Loss: 0.10436848950386048, Accuracy: 0.56\n",
      "Epoch 285, Loss: 0.10434399700164795, Accuracy: 0.56\n",
      "Epoch 286, Loss: 0.10431961703300476, Accuracy: 0.56\n",
      "Epoch 287, Loss: 0.10429535102844238, Accuracy: 0.56\n",
      "Epoch 288, Loss: 0.10427119421958923, Accuracy: 0.56\n",
      "Epoch 289, Loss: 0.10424715042114258, Accuracy: 0.56\n",
      "Epoch 290, Loss: 0.10422321486473084, Accuracy: 0.56\n",
      "Epoch 291, Loss: 0.10419938516616821, Accuracy: 0.56\n",
      "Epoch 292, Loss: 0.10417566394805908, Accuracy: 0.56\n",
      "Epoch 293, Loss: 0.10415204548835755, Accuracy: 0.56\n",
      "Epoch 294, Loss: 0.10412853360176086, Accuracy: 0.57\n",
      "Epoch 295, Loss: 0.10410512351989747, Accuracy: 0.57\n",
      "Epoch 296, Loss: 0.10408181548118592, Accuracy: 0.57\n",
      "Epoch 297, Loss: 0.10405860829353332, Accuracy: 0.57\n",
      "Epoch 298, Loss: 0.1040354995727539, Accuracy: 0.57\n",
      "Epoch 299, Loss: 0.10401248788833618, Accuracy: 0.57\n",
      "Epoch 300, Loss: 0.10398957490921021, Accuracy: 0.57\n",
      "Epoch 301, Loss: 0.10396675896644593, Accuracy: 0.57\n",
      "Epoch 302, Loss: 0.10394403958320618, Accuracy: 0.56\n",
      "Epoch 303, Loss: 0.10392141151428223, Accuracy: 0.56\n",
      "Epoch 304, Loss: 0.10389887976646424, Accuracy: 0.56\n",
      "Epoch 305, Loss: 0.10387643599510193, Accuracy: 0.57\n",
      "Epoch 306, Loss: 0.10385408616065979, Accuracy: 0.57\n",
      "Epoch 307, Loss: 0.10383182764053345, Accuracy: 0.57\n",
      "Epoch 308, Loss: 0.10380965948104859, Accuracy: 0.57\n",
      "Epoch 309, Loss: 0.10378757905960083, Accuracy: 0.57\n",
      "Epoch 310, Loss: 0.10376558876037598, Accuracy: 0.57\n",
      "Epoch 311, Loss: 0.1037436821460724, Accuracy: 0.57\n",
      "Epoch 312, Loss: 0.10372186756134033, Accuracy: 0.57\n",
      "Epoch 313, Loss: 0.10370013451576233, Accuracy: 0.57\n",
      "Epoch 314, Loss: 0.10367848825454712, Accuracy: 0.57\n",
      "Epoch 315, Loss: 0.10365692687034607, Accuracy: 0.56\n",
      "Epoch 316, Loss: 0.10363544869422912, Accuracy: 0.56\n",
      "Epoch 317, Loss: 0.10361405181884766, Accuracy: 0.56\n",
      "Epoch 318, Loss: 0.10359274005889893, Accuracy: 0.56\n",
      "Epoch 319, Loss: 0.10357150864601135, Accuracy: 0.56\n",
      "Epoch 320, Loss: 0.10355035781860351, Accuracy: 0.56\n",
      "Epoch 321, Loss: 0.10352929043769836, Accuracy: 0.56\n",
      "Epoch 322, Loss: 0.10350830125808716, Accuracy: 0.56\n",
      "Epoch 323, Loss: 0.10348739004135132, Accuracy: 0.56\n",
      "Epoch 324, Loss: 0.10346655797958373, Accuracy: 0.56\n",
      "Epoch 325, Loss: 0.10344580602645874, Accuracy: 0.56\n",
      "Epoch 326, Loss: 0.10342512822151184, Accuracy: 0.56\n",
      "Epoch 327, Loss: 0.1034045295715332, Accuracy: 0.56\n",
      "Epoch 328, Loss: 0.10338400626182556, Accuracy: 0.56\n",
      "Epoch 329, Loss: 0.10336355900764466, Accuracy: 0.56\n",
      "Epoch 330, Loss: 0.103343186378479, Accuracy: 0.56\n",
      "Epoch 331, Loss: 0.10332288837432861, Accuracy: 0.56\n",
      "Epoch 332, Loss: 0.10330266642570496, Accuracy: 0.56\n",
      "Epoch 333, Loss: 0.10328251552581787, Accuracy: 0.56\n",
      "Epoch 334, Loss: 0.1032624409198761, Accuracy: 0.56\n",
      "Epoch 335, Loss: 0.10324243831634522, Accuracy: 0.56\n",
      "Epoch 336, Loss: 0.10322250390052795, Accuracy: 0.56\n",
      "Epoch 337, Loss: 0.10320264601707459, Accuracy: 0.56\n",
      "Epoch 338, Loss: 0.10318285465240479, Accuracy: 0.56\n",
      "Epoch 339, Loss: 0.10316313743591309, Accuracy: 0.56\n",
      "Epoch 340, Loss: 0.10314348888397216, Accuracy: 0.56\n",
      "Epoch 341, Loss: 0.10312391042709351, Accuracy: 0.56\n",
      "Epoch 342, Loss: 0.10310439991950988, Accuracy: 0.56\n",
      "Epoch 343, Loss: 0.10308496165275574, Accuracy: 0.56\n",
      "Epoch 344, Loss: 0.103065589427948, Accuracy: 0.56\n",
      "Epoch 345, Loss: 0.10304628467559815, Accuracy: 0.56\n",
      "Epoch 346, Loss: 0.10302704644203187, Accuracy: 0.56\n",
      "Epoch 347, Loss: 0.10300787496566773, Accuracy: 0.56\n",
      "Epoch 348, Loss: 0.10298877263069153, Accuracy: 0.56\n",
      "Epoch 349, Loss: 0.10296973347663879, Accuracy: 0.56\n",
      "Epoch 350, Loss: 0.1029507610797882, Accuracy: 0.56\n",
      "Epoch 351, Loss: 0.10293185210227966, Accuracy: 0.56\n",
      "Epoch 352, Loss: 0.10291300988197327, Accuracy: 0.56\n",
      "Epoch 353, Loss: 0.10289423036575317, Accuracy: 0.56\n",
      "Epoch 354, Loss: 0.10287551307678222, Accuracy: 0.56\n",
      "Epoch 355, Loss: 0.10285686182975769, Accuracy: 0.56\n",
      "Epoch 356, Loss: 0.10283827090263367, Accuracy: 0.56\n",
      "Epoch 357, Loss: 0.102819744348526, Accuracy: 0.56\n",
      "Epoch 358, Loss: 0.10280127882957459, Accuracy: 0.56\n",
      "Epoch 359, Loss: 0.10278287506103516, Accuracy: 0.56\n",
      "Epoch 360, Loss: 0.10276453113555908, Accuracy: 0.56\n",
      "Epoch 361, Loss: 0.10274624848365783, Accuracy: 0.56\n",
      "Epoch 362, Loss: 0.10272802805900574, Accuracy: 0.56\n",
      "Epoch 363, Loss: 0.1027098639011383, Accuracy: 0.56\n",
      "Epoch 364, Loss: 0.10269176149368286, Accuracy: 0.56\n",
      "Epoch 365, Loss: 0.10267371773719787, Accuracy: 0.56\n",
      "Epoch 366, Loss: 0.10265572881698608, Accuracy: 0.56\n",
      "Epoch 367, Loss: 0.10263780331611633, Accuracy: 0.56\n",
      "Epoch 368, Loss: 0.10261993098258972, Accuracy: 0.56\n",
      "Epoch 369, Loss: 0.10260211706161498, Accuracy: 0.56\n",
      "Epoch 370, Loss: 0.10258436059951782, Accuracy: 0.56\n",
      "Epoch 371, Loss: 0.1025666606426239, Accuracy: 0.56\n",
      "Epoch 372, Loss: 0.10254901623725891, Accuracy: 0.56\n",
      "Epoch 373, Loss: 0.10253142762184143, Accuracy: 0.56\n",
      "Epoch 374, Loss: 0.10251389551162719, Accuracy: 0.56\n",
      "Epoch 375, Loss: 0.10249641609191895, Accuracy: 0.56\n",
      "Epoch 376, Loss: 0.10247898936271667, Accuracy: 0.56\n",
      "Epoch 377, Loss: 0.10246161985397338, Accuracy: 0.56\n",
      "Epoch 378, Loss: 0.10244430208206176, Accuracy: 0.56\n",
      "Epoch 379, Loss: 0.10242703700065613, Accuracy: 0.56\n",
      "Epoch 380, Loss: 0.10240982508659363, Accuracy: 0.56\n",
      "Epoch 381, Loss: 0.10239266705513, Accuracy: 0.56\n",
      "Epoch 382, Loss: 0.10237556028366089, Accuracy: 0.56\n",
      "Epoch 383, Loss: 0.10235850191116333, Accuracy: 0.56\n",
      "Epoch 384, Loss: 0.10234149742126465, Accuracy: 0.56\n",
      "Epoch 385, Loss: 0.10232454299926758, Accuracy: 0.57\n",
      "Epoch 386, Loss: 0.10230763936042786, Accuracy: 0.57\n",
      "Epoch 387, Loss: 0.10229078364372253, Accuracy: 0.57\n",
      "Epoch 388, Loss: 0.10227398037910461, Accuracy: 0.57\n",
      "Epoch 389, Loss: 0.10225722622871398, Accuracy: 0.57\n",
      "Epoch 390, Loss: 0.10224051856994629, Accuracy: 0.57\n",
      "Epoch 391, Loss: 0.10222386121749878, Accuracy: 0.57\n",
      "Epoch 392, Loss: 0.10220724868774414, Accuracy: 0.57\n",
      "Epoch 393, Loss: 0.10219068622589111, Accuracy: 0.57\n",
      "Epoch 394, Loss: 0.10217416954040527, Accuracy: 0.57\n",
      "Epoch 395, Loss: 0.10215770077705383, Accuracy: 0.57\n",
      "Epoch 396, Loss: 0.10214127850532531, Accuracy: 0.57\n",
      "Epoch 397, Loss: 0.1021249008178711, Accuracy: 0.57\n",
      "Epoch 398, Loss: 0.10210856890678406, Accuracy: 0.57\n",
      "Epoch 399, Loss: 0.10209228229522706, Accuracy: 0.57\n",
      "Epoch 400, Loss: 0.10207604098320007, Accuracy: 0.57\n",
      "Epoch 401, Loss: 0.10205984282493591, Accuracy: 0.57\n",
      "Epoch 402, Loss: 0.1020436897277832, Accuracy: 0.57\n",
      "Epoch 403, Loss: 0.1020275776386261, Accuracy: 0.57\n",
      "Epoch 404, Loss: 0.10201151061058045, Accuracy: 0.58\n",
      "Epoch 405, Loss: 0.10199548816680908, Accuracy: 0.58\n",
      "Epoch 406, Loss: 0.10197950625419616, Accuracy: 0.58\n",
      "Epoch 407, Loss: 0.10196356534957886, Accuracy: 0.58\n",
      "Epoch 408, Loss: 0.10194766902923584, Accuracy: 0.58\n",
      "Epoch 409, Loss: 0.10193181109428406, Accuracy: 0.58\n",
      "Epoch 410, Loss: 0.10191599416732788, Accuracy: 0.58\n",
      "Epoch 411, Loss: 0.10190021991729736, Accuracy: 0.58\n",
      "Epoch 412, Loss: 0.10188448238372803, Accuracy: 0.58\n",
      "Epoch 413, Loss: 0.1018687858581543, Accuracy: 0.58\n",
      "Epoch 414, Loss: 0.10185312914848328, Accuracy: 0.58\n",
      "Epoch 415, Loss: 0.10183751034736634, Accuracy: 0.58\n",
      "Epoch 416, Loss: 0.10182193017005921, Accuracy: 0.58\n",
      "Epoch 417, Loss: 0.10180639004707337, Accuracy: 0.58\n",
      "Epoch 418, Loss: 0.10179088449478149, Accuracy: 0.58\n",
      "Epoch 419, Loss: 0.10177541828155517, Accuracy: 0.58\n",
      "Epoch 420, Loss: 0.10175998854637146, Accuracy: 0.58\n",
      "Epoch 421, Loss: 0.10174459409713744, Accuracy: 0.58\n",
      "Epoch 422, Loss: 0.10172923612594605, Accuracy: 0.58\n",
      "Epoch 423, Loss: 0.10171391582489013, Accuracy: 0.58\n",
      "Epoch 424, Loss: 0.10169862651824951, Accuracy: 0.58\n",
      "Epoch 425, Loss: 0.10168337631225587, Accuracy: 0.58\n",
      "Epoch 426, Loss: 0.10166815948486328, Accuracy: 0.57\n",
      "Epoch 427, Loss: 0.10165297770500183, Accuracy: 0.57\n",
      "Epoch 428, Loss: 0.10163782691955567, Accuracy: 0.57\n",
      "Epoch 429, Loss: 0.1016227126121521, Accuracy: 0.57\n",
      "Epoch 430, Loss: 0.10160762906074523, Accuracy: 0.57\n",
      "Epoch 431, Loss: 0.10159258246421814, Accuracy: 0.57\n",
      "Epoch 432, Loss: 0.10157756447792053, Accuracy: 0.57\n",
      "Epoch 433, Loss: 0.10156258058547973, Accuracy: 0.57\n",
      "Epoch 434, Loss: 0.10154762673377991, Accuracy: 0.57\n",
      "Epoch 435, Loss: 0.1015327033996582, Accuracy: 0.57\n",
      "Epoch 436, Loss: 0.10151781296730042, Accuracy: 0.57\n",
      "Epoch 437, Loss: 0.10150295066833497, Accuracy: 0.57\n",
      "Epoch 438, Loss: 0.10148812317848206, Accuracy: 0.57\n",
      "Epoch 439, Loss: 0.10147332286834716, Accuracy: 0.57\n",
      "Epoch 440, Loss: 0.10145855283737183, Accuracy: 0.57\n",
      "Epoch 441, Loss: 0.1014438133239746, Accuracy: 0.57\n",
      "Epoch 442, Loss: 0.10142910099029541, Accuracy: 0.57\n",
      "Epoch 443, Loss: 0.10141442012786865, Accuracy: 0.57\n",
      "Epoch 444, Loss: 0.10139976501464844, Accuracy: 0.57\n",
      "Epoch 445, Loss: 0.10138513994216919, Accuracy: 0.57\n",
      "Epoch 446, Loss: 0.1013705427646637, Accuracy: 0.57\n",
      "Epoch 447, Loss: 0.10135597276687622, Accuracy: 0.57\n",
      "Epoch 448, Loss: 0.10134143114089966, Accuracy: 0.57\n",
      "Epoch 449, Loss: 0.10132691407203674, Accuracy: 0.57\n",
      "Epoch 450, Loss: 0.1013124279975891, Accuracy: 0.57\n",
      "Epoch 451, Loss: 0.10129796814918518, Accuracy: 0.57\n",
      "Epoch 452, Loss: 0.10128353428840638, Accuracy: 0.58\n",
      "Epoch 453, Loss: 0.101269127368927, Accuracy: 0.58\n",
      "Epoch 454, Loss: 0.10125474643707276, Accuracy: 0.58\n",
      "Epoch 455, Loss: 0.10124039125442505, Accuracy: 0.58\n",
      "Epoch 456, Loss: 0.10122606444358825, Accuracy: 0.58\n",
      "Epoch 457, Loss: 0.1012117624282837, Accuracy: 0.58\n",
      "Epoch 458, Loss: 0.10119748616218567, Accuracy: 0.58\n",
      "Epoch 459, Loss: 0.10118323445320129, Accuracy: 0.58\n",
      "Epoch 460, Loss: 0.1011690125465393, Accuracy: 0.58\n",
      "Epoch 461, Loss: 0.10115481233596801, Accuracy: 0.58\n",
      "Epoch 462, Loss: 0.10114063882827759, Accuracy: 0.58\n",
      "Epoch 463, Loss: 0.10112649154663086, Accuracy: 0.59\n",
      "Epoch 464, Loss: 0.10111236977577209, Accuracy: 0.59\n",
      "Epoch 465, Loss: 0.10109827327728271, Accuracy: 0.59\n",
      "Epoch 466, Loss: 0.10108420205116272, Accuracy: 0.59\n",
      "Epoch 467, Loss: 0.10107015705108642, Accuracy: 0.59\n",
      "Epoch 468, Loss: 0.1010561375617981, Accuracy: 0.59\n",
      "Epoch 469, Loss: 0.10104214382171631, Accuracy: 0.59\n",
      "Epoch 470, Loss: 0.10102817487716675, Accuracy: 0.59\n",
      "Epoch 471, Loss: 0.10101423215866089, Accuracy: 0.59\n",
      "Epoch 472, Loss: 0.101000314950943, Accuracy: 0.59\n",
      "Epoch 473, Loss: 0.10098642325401307, Accuracy: 0.59\n",
      "Epoch 474, Loss: 0.1009725604057312, Accuracy: 0.59\n",
      "Epoch 475, Loss: 0.10095871806144714, Accuracy: 0.59\n",
      "Epoch 476, Loss: 0.10094490838050842, Accuracy: 0.59\n",
      "Epoch 477, Loss: 0.10093112230300903, Accuracy: 0.59\n",
      "Epoch 478, Loss: 0.10091735887527466, Accuracy: 0.59\n",
      "Epoch 479, Loss: 0.10090362620353699, Accuracy: 0.59\n",
      "Epoch 480, Loss: 0.10088992047309875, Accuracy: 0.59\n",
      "Epoch 481, Loss: 0.10087623882293702, Accuracy: 0.59\n",
      "Epoch 482, Loss: 0.10086258578300476, Accuracy: 0.59\n",
      "Epoch 483, Loss: 0.10084896111488342, Accuracy: 0.59\n",
      "Epoch 484, Loss: 0.10083536148071288, Accuracy: 0.59\n",
      "Epoch 485, Loss: 0.10082179141044617, Accuracy: 0.6\n",
      "Epoch 486, Loss: 0.10080824851989746, Accuracy: 0.6\n",
      "Epoch 487, Loss: 0.10079473090171814, Accuracy: 0.6\n",
      "Epoch 488, Loss: 0.10078124356269837, Accuracy: 0.6\n",
      "Epoch 489, Loss: 0.10076778292655945, Accuracy: 0.6\n",
      "Epoch 490, Loss: 0.10075435519218445, Accuracy: 0.6\n",
      "Epoch 491, Loss: 0.10074095344543457, Accuracy: 0.6\n",
      "Epoch 492, Loss: 0.10072757840156556, Accuracy: 0.6\n",
      "Epoch 493, Loss: 0.10071423649787903, Accuracy: 0.6\n",
      "Epoch 494, Loss: 0.10070092058181762, Accuracy: 0.6\n",
      "Epoch 495, Loss: 0.10068763780593872, Accuracy: 0.6\n",
      "Epoch 496, Loss: 0.10067437934875488, Accuracy: 0.6\n",
      "Epoch 497, Loss: 0.10066115641593933, Accuracy: 0.6\n",
      "Epoch 498, Loss: 0.10064796209335328, Accuracy: 0.6\n",
      "Epoch 499, Loss: 0.10063479924201965, Accuracy: 0.6\n",
      "Epoch 500, Loss: 0.10062166571617126, Accuracy: 0.6\n",
      "Epoch 501, Loss: 0.10060856318473815, Accuracy: 0.6\n",
      "Epoch 502, Loss: 0.10059549379348755, Accuracy: 0.59\n",
      "Epoch 503, Loss: 0.10058245635032653, Accuracy: 0.59\n",
      "Epoch 504, Loss: 0.10056944942474365, Accuracy: 0.58\n",
      "Epoch 505, Loss: 0.10055647540092469, Accuracy: 0.58\n",
      "Epoch 506, Loss: 0.10054353618621827, Accuracy: 0.58\n",
      "Epoch 507, Loss: 0.10053062605857849, Accuracy: 0.58\n",
      "Epoch 508, Loss: 0.10051774907112121, Accuracy: 0.58\n",
      "Epoch 509, Loss: 0.1005049078464508, Accuracy: 0.59\n",
      "Epoch 510, Loss: 0.10049209904670715, Accuracy: 0.59\n",
      "Epoch 511, Loss: 0.10047932648658753, Accuracy: 0.59\n",
      "Epoch 512, Loss: 0.10046658778190613, Accuracy: 0.59\n",
      "Epoch 513, Loss: 0.10045388221740723, Accuracy: 0.59\n",
      "Epoch 514, Loss: 0.10044121336936951, Accuracy: 0.59\n",
      "Epoch 515, Loss: 0.10042857837677002, Accuracy: 0.59\n",
      "Epoch 516, Loss: 0.10041597890853882, Accuracy: 0.59\n",
      "Epoch 517, Loss: 0.10040341758728027, Accuracy: 0.59\n",
      "Epoch 518, Loss: 0.10039089202880859, Accuracy: 0.59\n",
      "Epoch 519, Loss: 0.10037840175628662, Accuracy: 0.59\n",
      "Epoch 520, Loss: 0.10036594939231873, Accuracy: 0.59\n",
      "Epoch 521, Loss: 0.10035353255271912, Accuracy: 0.59\n",
      "Epoch 522, Loss: 0.10034115886688233, Accuracy: 0.59\n",
      "Epoch 523, Loss: 0.10032881736755371, Accuracy: 0.59\n",
      "Epoch 524, Loss: 0.10031651639938355, Accuracy: 0.59\n",
      "Epoch 525, Loss: 0.10030425214767456, Accuracy: 0.59\n",
      "Epoch 526, Loss: 0.10029202723503113, Accuracy: 0.59\n",
      "Epoch 527, Loss: 0.1002798421382904, Accuracy: 0.58\n",
      "Epoch 528, Loss: 0.10026769614219666, Accuracy: 0.58\n",
      "Epoch 529, Loss: 0.10025558757781983, Accuracy: 0.58\n",
      "Epoch 530, Loss: 0.10024352145195008, Accuracy: 0.58\n",
      "Epoch 531, Loss: 0.10023149251937866, Accuracy: 0.58\n",
      "Epoch 532, Loss: 0.10021950602531433, Accuracy: 0.58\n",
      "Epoch 533, Loss: 0.10020755815505981, Accuracy: 0.58\n",
      "Epoch 534, Loss: 0.10019564914703369, Accuracy: 0.58\n",
      "Epoch 535, Loss: 0.10018378353118897, Accuracy: 0.58\n",
      "Epoch 536, Loss: 0.100171954870224, Accuracy: 0.58\n",
      "Epoch 537, Loss: 0.10016016936302186, Accuracy: 0.58\n",
      "Epoch 538, Loss: 0.10014842247962952, Accuracy: 0.58\n",
      "Epoch 539, Loss: 0.10013671779632569, Accuracy: 0.58\n",
      "Epoch 540, Loss: 0.10012505316734314, Accuracy: 0.58\n",
      "Epoch 541, Loss: 0.10011342859268188, Accuracy: 0.58\n",
      "Epoch 542, Loss: 0.10010184526443482, Accuracy: 0.58\n",
      "Epoch 543, Loss: 0.1000903024673462, Accuracy: 0.58\n",
      "Epoch 544, Loss: 0.10007880115509034, Accuracy: 0.58\n",
      "Epoch 545, Loss: 0.10006733965873718, Accuracy: 0.58\n",
      "Epoch 546, Loss: 0.10005591773986816, Accuracy: 0.58\n",
      "Epoch 547, Loss: 0.1000445339679718, Accuracy: 0.58\n",
      "Epoch 548, Loss: 0.1000331916809082, Accuracy: 0.58\n",
      "Epoch 549, Loss: 0.10002188968658447, Accuracy: 0.58\n",
      "Epoch 550, Loss: 0.10001062607765197, Accuracy: 0.58\n",
      "Epoch 551, Loss: 0.09999940323829651, Accuracy: 0.58\n",
      "Epoch 552, Loss: 0.09998821878433227, Accuracy: 0.58\n",
      "Epoch 553, Loss: 0.09997707533836364, Accuracy: 0.58\n",
      "Epoch 554, Loss: 0.09996597003936768, Accuracy: 0.58\n",
      "Epoch 555, Loss: 0.09995490169525147, Accuracy: 0.58\n",
      "Epoch 556, Loss: 0.09994387197494507, Accuracy: 0.58\n",
      "Epoch 557, Loss: 0.09993288040161133, Accuracy: 0.58\n",
      "Epoch 558, Loss: 0.0999219274520874, Accuracy: 0.58\n",
      "Epoch 559, Loss: 0.09991101121902465, Accuracy: 0.58\n",
      "Epoch 560, Loss: 0.09990013337135314, Accuracy: 0.58\n",
      "Epoch 561, Loss: 0.09988929152488708, Accuracy: 0.58\n",
      "Epoch 562, Loss: 0.0998784875869751, Accuracy: 0.58\n",
      "Epoch 563, Loss: 0.09986771678924561, Accuracy: 0.58\n",
      "Epoch 564, Loss: 0.0998569848537445, Accuracy: 0.58\n",
      "Epoch 565, Loss: 0.09984628796577454, Accuracy: 0.58\n",
      "Epoch 566, Loss: 0.09983562803268432, Accuracy: 0.58\n",
      "Epoch 567, Loss: 0.09982500195503236, Accuracy: 0.58\n",
      "Epoch 568, Loss: 0.09981441164016723, Accuracy: 0.58\n",
      "Epoch 569, Loss: 0.0998038558959961, Accuracy: 0.58\n",
      "Epoch 570, Loss: 0.09979333376884461, Accuracy: 0.58\n",
      "Epoch 571, Loss: 0.09978284740447999, Accuracy: 0.58\n",
      "Epoch 572, Loss: 0.09977239322662354, Accuracy: 0.58\n",
      "Epoch 573, Loss: 0.09976197361946106, Accuracy: 0.58\n",
      "Epoch 574, Loss: 0.09975158810615539, Accuracy: 0.58\n",
      "Epoch 575, Loss: 0.09974123477935791, Accuracy: 0.58\n",
      "Epoch 576, Loss: 0.09973091363906861, Accuracy: 0.58\n",
      "Epoch 577, Loss: 0.09972062492370605, Accuracy: 0.58\n",
      "Epoch 578, Loss: 0.09971037101745606, Accuracy: 0.58\n",
      "Epoch 579, Loss: 0.09970014715194703, Accuracy: 0.58\n",
      "Epoch 580, Loss: 0.09968995547294617, Accuracy: 0.58\n",
      "Epoch 581, Loss: 0.09967979407310486, Accuracy: 0.58\n",
      "Epoch 582, Loss: 0.09966966652870178, Accuracy: 0.58\n",
      "Epoch 583, Loss: 0.09965956807136536, Accuracy: 0.58\n",
      "Epoch 584, Loss: 0.09964950037002564, Accuracy: 0.58\n",
      "Epoch 585, Loss: 0.09963946390151977, Accuracy: 0.58\n",
      "Epoch 586, Loss: 0.09962945699691772, Accuracy: 0.58\n",
      "Epoch 587, Loss: 0.09961948156356812, Accuracy: 0.58\n",
      "Epoch 588, Loss: 0.09960953402519226, Accuracy: 0.58\n",
      "Epoch 589, Loss: 0.09959961771965027, Accuracy: 0.58\n",
      "Epoch 590, Loss: 0.09958973145484924, Accuracy: 0.58\n",
      "Epoch 591, Loss: 0.09957987356185913, Accuracy: 0.58\n",
      "Epoch 592, Loss: 0.09957004642486572, Accuracy: 0.58\n",
      "Epoch 593, Loss: 0.09956024336814881, Accuracy: 0.58\n",
      "Epoch 594, Loss: 0.09955047440528869, Accuracy: 0.58\n",
      "Epoch 595, Loss: 0.09954073071479798, Accuracy: 0.58\n",
      "Epoch 596, Loss: 0.09953101873397827, Accuracy: 0.58\n",
      "Epoch 597, Loss: 0.09952133274078369, Accuracy: 0.58\n",
      "Epoch 598, Loss: 0.09951167488098145, Accuracy: 0.58\n",
      "Epoch 599, Loss: 0.09950204277038574, Accuracy: 0.58\n",
      "Epoch 600, Loss: 0.09949244260787964, Accuracy: 0.58\n",
      "Epoch 601, Loss: 0.09948286700248718, Accuracy: 0.58\n",
      "Epoch 602, Loss: 0.09947331905364991, Accuracy: 0.58\n",
      "Epoch 603, Loss: 0.09946380209922791, Accuracy: 0.58\n",
      "Epoch 604, Loss: 0.0994543080329895, Accuracy: 0.58\n",
      "Epoch 605, Loss: 0.09944484233856202, Accuracy: 0.58\n",
      "Epoch 606, Loss: 0.09943540382385253, Accuracy: 0.58\n",
      "Epoch 607, Loss: 0.09942599391937255, Accuracy: 0.58\n",
      "Epoch 608, Loss: 0.0994166066646576, Accuracy: 0.58\n",
      "Epoch 609, Loss: 0.0994072482585907, Accuracy: 0.58\n",
      "Epoch 610, Loss: 0.09939791750907898, Accuracy: 0.58\n",
      "Epoch 611, Loss: 0.09938860964775086, Accuracy: 0.58\n",
      "Epoch 612, Loss: 0.09937932991981506, Accuracy: 0.59\n",
      "Epoch 613, Loss: 0.09937007665634155, Accuracy: 0.59\n",
      "Epoch 614, Loss: 0.09936084914207459, Accuracy: 0.59\n",
      "Epoch 615, Loss: 0.09935164737701416, Accuracy: 0.59\n",
      "Epoch 616, Loss: 0.09934247159957886, Accuracy: 0.59\n",
      "Epoch 617, Loss: 0.09933332085609436, Accuracy: 0.59\n",
      "Epoch 618, Loss: 0.09932419538497925, Accuracy: 0.59\n",
      "Epoch 619, Loss: 0.09931509780883789, Accuracy: 0.59\n",
      "Epoch 620, Loss: 0.0993060245513916, Accuracy: 0.59\n",
      "Epoch 621, Loss: 0.09929697346687318, Accuracy: 0.59\n",
      "Epoch 622, Loss: 0.09928795218467712, Accuracy: 0.59\n",
      "Epoch 623, Loss: 0.09927895379066468, Accuracy: 0.59\n",
      "Epoch 624, Loss: 0.09926998209953308, Accuracy: 0.59\n",
      "Epoch 625, Loss: 0.09926103663444519, Accuracy: 0.59\n",
      "Epoch 626, Loss: 0.09925211191177369, Accuracy: 0.59\n",
      "Epoch 627, Loss: 0.09924321556091309, Accuracy: 0.59\n",
      "Epoch 628, Loss: 0.09923434448242187, Accuracy: 0.59\n",
      "Epoch 629, Loss: 0.09922549748420716, Accuracy: 0.59\n",
      "Epoch 630, Loss: 0.0992166748046875, Accuracy: 0.59\n",
      "Epoch 631, Loss: 0.09920787715911865, Accuracy: 0.59\n",
      "Epoch 632, Loss: 0.09919910430908203, Accuracy: 0.59\n",
      "Epoch 633, Loss: 0.09919035696983337, Accuracy: 0.59\n",
      "Epoch 634, Loss: 0.09918163251876831, Accuracy: 0.59\n",
      "Epoch 635, Loss: 0.0991729338169098, Accuracy: 0.59\n",
      "Epoch 636, Loss: 0.09916426181793213, Accuracy: 0.59\n",
      "Epoch 637, Loss: 0.09915561318397521, Accuracy: 0.59\n",
      "Epoch 638, Loss: 0.09914698481559753, Accuracy: 0.59\n",
      "Epoch 639, Loss: 0.09913838529586792, Accuracy: 0.59\n",
      "Epoch 640, Loss: 0.09912980961799621, Accuracy: 0.59\n",
      "Epoch 641, Loss: 0.09912125706672668, Accuracy: 0.59\n",
      "Epoch 642, Loss: 0.09911272883415222, Accuracy: 0.59\n",
      "Epoch 643, Loss: 0.09910422778129578, Accuracy: 0.59\n",
      "Epoch 644, Loss: 0.09909574818611146, Accuracy: 0.59\n",
      "Epoch 645, Loss: 0.09908729362487793, Accuracy: 0.59\n",
      "Epoch 646, Loss: 0.09907886457443238, Accuracy: 0.59\n",
      "Epoch 647, Loss: 0.09907045793533326, Accuracy: 0.59\n",
      "Epoch 648, Loss: 0.09906207513809204, Accuracy: 0.59\n",
      "Epoch 649, Loss: 0.09905371594429016, Accuracy: 0.59\n",
      "Epoch 650, Loss: 0.09904538202285766, Accuracy: 0.59\n",
      "Epoch 651, Loss: 0.09903707242012023, Accuracy: 0.59\n",
      "Epoch 652, Loss: 0.09902878880500793, Accuracy: 0.59\n",
      "Epoch 653, Loss: 0.09902052307128906, Accuracy: 0.59\n",
      "Epoch 654, Loss: 0.099012286901474, Accuracy: 0.59\n",
      "Epoch 655, Loss: 0.0990040717124939, Accuracy: 0.59\n",
      "Epoch 656, Loss: 0.09899588203430176, Accuracy: 0.59\n",
      "Epoch 657, Loss: 0.09898771739006043, Accuracy: 0.59\n",
      "Epoch 658, Loss: 0.09897957587242126, Accuracy: 0.59\n",
      "Epoch 659, Loss: 0.09897145771980286, Accuracy: 0.59\n",
      "Epoch 660, Loss: 0.09896336150169373, Accuracy: 0.59\n",
      "Epoch 661, Loss: 0.09895529103279113, Accuracy: 0.59\n",
      "Epoch 662, Loss: 0.09894724321365357, Accuracy: 0.59\n",
      "Epoch 663, Loss: 0.09893922138214112, Accuracy: 0.59\n",
      "Epoch 664, Loss: 0.09893122005462647, Accuracy: 0.59\n",
      "Epoch 665, Loss: 0.09892324328422547, Accuracy: 0.59\n",
      "Epoch 666, Loss: 0.09891529154777527, Accuracy: 0.59\n",
      "Epoch 667, Loss: 0.09890736413002015, Accuracy: 0.59\n",
      "Epoch 668, Loss: 0.09889945721626282, Accuracy: 0.59\n",
      "Epoch 669, Loss: 0.09889157581329346, Accuracy: 0.59\n",
      "Epoch 670, Loss: 0.09888371610641479, Accuracy: 0.59\n",
      "Epoch 671, Loss: 0.09887588191032409, Accuracy: 0.59\n",
      "Epoch 672, Loss: 0.09886806964874267, Accuracy: 0.59\n",
      "Epoch 673, Loss: 0.09886027932167053, Accuracy: 0.59\n",
      "Epoch 674, Loss: 0.09885251569747924, Accuracy: 0.59\n",
      "Epoch 675, Loss: 0.09884477233886718, Accuracy: 0.59\n",
      "Epoch 676, Loss: 0.09883705401420594, Accuracy: 0.59\n",
      "Epoch 677, Loss: 0.09882935976982117, Accuracy: 0.59\n",
      "Epoch 678, Loss: 0.09882168793678284, Accuracy: 0.59\n",
      "Epoch 679, Loss: 0.0988140377998352, Accuracy: 0.59\n",
      "Epoch 680, Loss: 0.09880641269683837, Accuracy: 0.59\n",
      "Epoch 681, Loss: 0.09879880905151367, Accuracy: 0.59\n",
      "Epoch 682, Loss: 0.09879123044013977, Accuracy: 0.59\n",
      "Epoch 683, Loss: 0.09878367114067077, Accuracy: 0.59\n",
      "Epoch 684, Loss: 0.09877613782882691, Accuracy: 0.59\n",
      "Epoch 685, Loss: 0.09876862525939942, Accuracy: 0.59\n",
      "Epoch 686, Loss: 0.09876113724708557, Accuracy: 0.59\n",
      "Epoch 687, Loss: 0.09875367140769958, Accuracy: 0.59\n",
      "Epoch 688, Loss: 0.09874622797966004, Accuracy: 0.59\n",
      "Epoch 689, Loss: 0.0987388060092926, Accuracy: 0.59\n",
      "Epoch 690, Loss: 0.09873140931129455, Accuracy: 0.59\n",
      "Epoch 691, Loss: 0.09872403478622437, Accuracy: 0.59\n",
      "Epoch 692, Loss: 0.09871668028831482, Accuracy: 0.59\n",
      "Epoch 693, Loss: 0.09870935273170471, Accuracy: 0.59\n",
      "Epoch 694, Loss: 0.09870204210281372, Accuracy: 0.59\n",
      "Epoch 695, Loss: 0.09869475650787353, Accuracy: 0.59\n",
      "Epoch 696, Loss: 0.09868749380111694, Accuracy: 0.59\n",
      "Epoch 697, Loss: 0.09868025255203247, Accuracy: 0.59\n",
      "Epoch 698, Loss: 0.09867303323745727, Accuracy: 0.59\n",
      "Epoch 699, Loss: 0.09866583776473999, Accuracy: 0.59\n",
      "Epoch 700, Loss: 0.09865866088867188, Accuracy: 0.59\n",
      "Epoch 701, Loss: 0.09865150952339172, Accuracy: 0.59\n",
      "Epoch 702, Loss: 0.09864437866210937, Accuracy: 0.59\n",
      "Epoch 703, Loss: 0.0986372697353363, Accuracy: 0.59\n",
      "Epoch 704, Loss: 0.09863018488883972, Accuracy: 0.59\n",
      "Epoch 705, Loss: 0.0986231210231781, Accuracy: 0.59\n",
      "Epoch 706, Loss: 0.09861607646942139, Accuracy: 0.59\n",
      "Epoch 707, Loss: 0.09860905504226684, Accuracy: 0.59\n",
      "Epoch 708, Loss: 0.09860205602645875, Accuracy: 0.59\n",
      "Epoch 709, Loss: 0.09859507727622986, Accuracy: 0.59\n",
      "Epoch 710, Loss: 0.09858811950683594, Accuracy: 0.59\n",
      "Epoch 711, Loss: 0.09858118605613708, Accuracy: 0.59\n",
      "Epoch 712, Loss: 0.09857427167892456, Accuracy: 0.59\n",
      "Epoch 713, Loss: 0.09856737852096557, Accuracy: 0.6\n",
      "Epoch 714, Loss: 0.09856050777435303, Accuracy: 0.6\n",
      "Epoch 715, Loss: 0.0985536596775055, Accuracy: 0.6\n",
      "Epoch 716, Loss: 0.09854682922363281, Accuracy: 0.6\n",
      "Epoch 717, Loss: 0.0985400230884552, Accuracy: 0.6\n",
      "Epoch 718, Loss: 0.09853323459625245, Accuracy: 0.6\n",
      "Epoch 719, Loss: 0.09852647161483764, Accuracy: 0.6\n",
      "Epoch 720, Loss: 0.09851972699165344, Accuracy: 0.6\n",
      "Epoch 721, Loss: 0.09851300120353698, Accuracy: 0.6\n",
      "Epoch 722, Loss: 0.09850629997253418, Accuracy: 0.6\n",
      "Epoch 723, Loss: 0.09849961876869201, Accuracy: 0.6\n",
      "Epoch 724, Loss: 0.0984929563999176, Accuracy: 0.6\n",
      "Epoch 725, Loss: 0.09848631477355957, Accuracy: 0.6\n",
      "Epoch 726, Loss: 0.09847969388961791, Accuracy: 0.6\n",
      "Epoch 727, Loss: 0.0984730966091156, Accuracy: 0.6\n",
      "Epoch 728, Loss: 0.09846651673316956, Accuracy: 0.6\n",
      "Epoch 729, Loss: 0.09845995783805847, Accuracy: 0.6\n",
      "Epoch 730, Loss: 0.09845342087745666, Accuracy: 0.6\n",
      "Epoch 731, Loss: 0.09844690036773682, Accuracy: 0.6\n",
      "Epoch 732, Loss: 0.09844040489196777, Accuracy: 0.6\n",
      "Epoch 733, Loss: 0.09843392539024352, Accuracy: 0.6\n",
      "Epoch 734, Loss: 0.0984274673461914, Accuracy: 0.6\n",
      "Epoch 735, Loss: 0.09842102885246277, Accuracy: 0.6\n",
      "Epoch 736, Loss: 0.09841461420059204, Accuracy: 0.6\n",
      "Epoch 737, Loss: 0.09840821361541748, Accuracy: 0.6\n",
      "Epoch 738, Loss: 0.09840183401107788, Accuracy: 0.6\n",
      "Epoch 739, Loss: 0.09839547538757325, Accuracy: 0.6\n",
      "Epoch 740, Loss: 0.0983891351222992, Accuracy: 0.6\n",
      "Epoch 741, Loss: 0.09838281774520874, Accuracy: 0.6\n",
      "Epoch 742, Loss: 0.09837651920318603, Accuracy: 0.6\n",
      "Epoch 743, Loss: 0.09837023711204529, Accuracy: 0.6\n",
      "Epoch 744, Loss: 0.09836397647857666, Accuracy: 0.6\n",
      "Epoch 745, Loss: 0.09835773587226868, Accuracy: 0.6\n",
      "Epoch 746, Loss: 0.09835151410102844, Accuracy: 0.6\n",
      "Epoch 747, Loss: 0.09834531021118165, Accuracy: 0.6\n",
      "Epoch 748, Loss: 0.09833912444114686, Accuracy: 0.6\n",
      "Epoch 749, Loss: 0.09833295941352845, Accuracy: 0.6\n",
      "Epoch 750, Loss: 0.09832681345939637, Accuracy: 0.6\n",
      "Epoch 751, Loss: 0.09832068610191345, Accuracy: 0.6\n",
      "Epoch 752, Loss: 0.09831457829475403, Accuracy: 0.6\n",
      "Epoch 753, Loss: 0.09830848932266235, Accuracy: 0.6\n",
      "Epoch 754, Loss: 0.09830241703987122, Accuracy: 0.6\n",
      "Epoch 755, Loss: 0.09829636573791505, Accuracy: 0.6\n",
      "Epoch 756, Loss: 0.09829033088684082, Accuracy: 0.6\n",
      "Epoch 757, Loss: 0.09828431582450867, Accuracy: 0.6\n",
      "Epoch 758, Loss: 0.09827831792831421, Accuracy: 0.6\n",
      "Epoch 759, Loss: 0.0982723400592804, Accuracy: 0.6\n",
      "Epoch 760, Loss: 0.09826637935638428, Accuracy: 0.6\n",
      "Epoch 761, Loss: 0.0982604386806488, Accuracy: 0.6\n",
      "Epoch 762, Loss: 0.0982545132637024, Accuracy: 0.6\n",
      "Epoch 763, Loss: 0.09824860906600952, Accuracy: 0.6\n",
      "Epoch 764, Loss: 0.09824271988868713, Accuracy: 0.6\n",
      "Epoch 765, Loss: 0.09823684906959533, Accuracy: 0.6\n",
      "Epoch 766, Loss: 0.09823099851608276, Accuracy: 0.6\n",
      "Epoch 767, Loss: 0.0982251627445221, Accuracy: 0.6\n",
      "Epoch 768, Loss: 0.09821934795379639, Accuracy: 0.6\n",
      "Epoch 769, Loss: 0.09821354794502259, Accuracy: 0.6\n",
      "Epoch 770, Loss: 0.098207768201828, Accuracy: 0.6\n",
      "Epoch 771, Loss: 0.09820200324058533, Accuracy: 0.6\n",
      "Epoch 772, Loss: 0.09819625902175903, Accuracy: 0.6\n",
      "Epoch 773, Loss: 0.09819052767753601, Accuracy: 0.6\n",
      "Epoch 774, Loss: 0.09818481516838073, Accuracy: 0.6\n",
      "Epoch 775, Loss: 0.09817912197113036, Accuracy: 0.6\n",
      "Epoch 776, Loss: 0.09817344665527344, Accuracy: 0.6\n",
      "Epoch 777, Loss: 0.09816778349876404, Accuracy: 0.6\n",
      "Epoch 778, Loss: 0.09816214179992676, Accuracy: 0.6\n",
      "Epoch 779, Loss: 0.09815651535987854, Accuracy: 0.61\n",
      "Epoch 780, Loss: 0.09815090656280517, Accuracy: 0.61\n",
      "Epoch 781, Loss: 0.09814531302452087, Accuracy: 0.61\n",
      "Epoch 782, Loss: 0.09813973546028137, Accuracy: 0.61\n",
      "Epoch 783, Loss: 0.09813417720794677, Accuracy: 0.61\n",
      "Epoch 784, Loss: 0.09812863326072693, Accuracy: 0.61\n",
      "Epoch 785, Loss: 0.09812310719490051, Accuracy: 0.61\n",
      "Epoch 786, Loss: 0.09811759757995606, Accuracy: 0.61\n",
      "Epoch 787, Loss: 0.09811210417747497, Accuracy: 0.61\n",
      "Epoch 788, Loss: 0.09810662412643432, Accuracy: 0.61\n",
      "Epoch 789, Loss: 0.09810116577148438, Accuracy: 0.61\n",
      "Epoch 790, Loss: 0.09809571981430054, Accuracy: 0.61\n",
      "Epoch 791, Loss: 0.09809029054641724, Accuracy: 0.61\n",
      "Epoch 792, Loss: 0.0980848798751831, Accuracy: 0.61\n",
      "Epoch 793, Loss: 0.09807948160171509, Accuracy: 0.61\n",
      "Epoch 794, Loss: 0.09807410168647766, Accuracy: 0.61\n",
      "Epoch 795, Loss: 0.09806873416900634, Accuracy: 0.61\n",
      "Epoch 796, Loss: 0.09806338477134705, Accuracy: 0.61\n",
      "Epoch 797, Loss: 0.0980580530166626, Accuracy: 0.61\n",
      "Epoch 798, Loss: 0.09805273270606994, Accuracy: 0.61\n",
      "Epoch 799, Loss: 0.09804743146896362, Accuracy: 0.61\n",
      "Epoch 800, Loss: 0.098042142868042, Accuracy: 0.61\n",
      "Epoch 801, Loss: 0.09803686928749085, Accuracy: 0.61\n",
      "Epoch 802, Loss: 0.09803161334991455, Accuracy: 0.61\n",
      "Epoch 803, Loss: 0.09802637147903442, Accuracy: 0.61\n",
      "Epoch 804, Loss: 0.0980211455821991, Accuracy: 0.61\n",
      "Epoch 805, Loss: 0.0980159342288971, Accuracy: 0.61\n",
      "Epoch 806, Loss: 0.0980107364654541, Accuracy: 0.61\n",
      "Epoch 807, Loss: 0.09800555658340454, Accuracy: 0.61\n",
      "Epoch 808, Loss: 0.0980003890991211, Accuracy: 0.61\n",
      "Epoch 809, Loss: 0.09799523711204529, Accuracy: 0.61\n",
      "Epoch 810, Loss: 0.09799010014533996, Accuracy: 0.61\n",
      "Epoch 811, Loss: 0.09798497986793518, Accuracy: 0.61\n",
      "Epoch 812, Loss: 0.09797986912727356, Accuracy: 0.61\n",
      "Epoch 813, Loss: 0.09797477626800537, Accuracy: 0.61\n",
      "Epoch 814, Loss: 0.09796969723701478, Accuracy: 0.61\n",
      "Epoch 815, Loss: 0.09796463251113892, Accuracy: 0.61\n",
      "Epoch 816, Loss: 0.09795958232879638, Accuracy: 0.61\n",
      "Epoch 817, Loss: 0.09795454788208008, Accuracy: 0.61\n",
      "Epoch 818, Loss: 0.09794952726364135, Accuracy: 0.61\n",
      "Epoch 819, Loss: 0.09794451785087585, Accuracy: 0.61\n",
      "Epoch 820, Loss: 0.09793952441215516, Accuracy: 0.61\n",
      "Epoch 821, Loss: 0.09793454504013062, Accuracy: 0.61\n",
      "Epoch 822, Loss: 0.09792957782745361, Accuracy: 0.61\n",
      "Epoch 823, Loss: 0.09792462658882141, Accuracy: 0.61\n",
      "Epoch 824, Loss: 0.09791968750953674, Accuracy: 0.61\n",
      "Epoch 825, Loss: 0.09791476225852966, Accuracy: 0.61\n",
      "Epoch 826, Loss: 0.09790985250473022, Accuracy: 0.61\n",
      "Epoch 827, Loss: 0.0979049551486969, Accuracy: 0.61\n",
      "Epoch 828, Loss: 0.09790007162094116, Accuracy: 0.61\n",
      "Epoch 829, Loss: 0.09789520049095154, Accuracy: 0.61\n",
      "Epoch 830, Loss: 0.0978903431892395, Accuracy: 0.61\n",
      "Epoch 831, Loss: 0.09788549900054931, Accuracy: 0.61\n",
      "Epoch 832, Loss: 0.09788066983222961, Accuracy: 0.61\n",
      "Epoch 833, Loss: 0.09787585282325745, Accuracy: 0.61\n",
      "Epoch 834, Loss: 0.09787104916572571, Accuracy: 0.61\n",
      "Epoch 835, Loss: 0.09786625862121583, Accuracy: 0.61\n",
      "Epoch 836, Loss: 0.097861478805542, Accuracy: 0.61\n",
      "Epoch 837, Loss: 0.0978567156791687, Accuracy: 0.61\n",
      "Epoch 838, Loss: 0.09785196185112, Accuracy: 0.61\n",
      "Epoch 839, Loss: 0.09784722185134888, Accuracy: 0.61\n",
      "Epoch 840, Loss: 0.09784249591827393, Accuracy: 0.61\n",
      "Epoch 841, Loss: 0.09783778214454651, Accuracy: 0.61\n",
      "Epoch 842, Loss: 0.09783308005332947, Accuracy: 0.61\n",
      "Epoch 843, Loss: 0.0978283920288086, Accuracy: 0.61\n",
      "Epoch 844, Loss: 0.0978237144947052, Accuracy: 0.61\n",
      "Epoch 845, Loss: 0.0978190507888794, Accuracy: 0.61\n",
      "Epoch 846, Loss: 0.09781440019607544, Accuracy: 0.61\n",
      "Epoch 847, Loss: 0.09780976152420044, Accuracy: 0.61\n",
      "Epoch 848, Loss: 0.09780513525009155, Accuracy: 0.61\n",
      "Epoch 849, Loss: 0.09780051946640014, Accuracy: 0.61\n",
      "Epoch 850, Loss: 0.09779591798782349, Accuracy: 0.61\n",
      "Epoch 851, Loss: 0.09779132676124573, Accuracy: 0.61\n",
      "Epoch 852, Loss: 0.09778674578666686, Accuracy: 0.61\n",
      "Epoch 853, Loss: 0.09778218126296997, Accuracy: 0.61\n",
      "Epoch 854, Loss: 0.0977776277065277, Accuracy: 0.61\n",
      "Epoch 855, Loss: 0.0977730839252472, Accuracy: 0.61\n",
      "Epoch 856, Loss: 0.09776855254173279, Accuracy: 0.61\n",
      "Epoch 857, Loss: 0.09776403450965881, Accuracy: 0.61\n",
      "Epoch 858, Loss: 0.0977595272064209, Accuracy: 0.61\n",
      "Epoch 859, Loss: 0.09775502896308899, Accuracy: 0.61\n",
      "Epoch 860, Loss: 0.0977505464553833, Accuracy: 0.61\n",
      "Epoch 861, Loss: 0.09774607229232789, Accuracy: 0.61\n",
      "Epoch 862, Loss: 0.09774161171913147, Accuracy: 0.61\n",
      "Epoch 863, Loss: 0.09773716235160827, Accuracy: 0.61\n",
      "Epoch 864, Loss: 0.09773272466659545, Accuracy: 0.61\n",
      "Epoch 865, Loss: 0.09772829604148865, Accuracy: 0.61\n",
      "Epoch 866, Loss: 0.09772388052940369, Accuracy: 0.61\n",
      "Epoch 867, Loss: 0.09771947622299194, Accuracy: 0.61\n",
      "Epoch 868, Loss: 0.09771508097648621, Accuracy: 0.61\n",
      "Epoch 869, Loss: 0.09771070098876954, Accuracy: 0.61\n",
      "Epoch 870, Loss: 0.09770632815361023, Accuracy: 0.61\n",
      "Epoch 871, Loss: 0.09770196628570557, Accuracy: 0.61\n",
      "Epoch 872, Loss: 0.09769761800765991, Accuracy: 0.61\n",
      "Epoch 873, Loss: 0.09769327926635742, Accuracy: 0.61\n",
      "Epoch 874, Loss: 0.09768895268440246, Accuracy: 0.61\n",
      "Epoch 875, Loss: 0.09768463611602783, Accuracy: 0.61\n",
      "Epoch 876, Loss: 0.09768032836914063, Accuracy: 0.61\n",
      "Epoch 877, Loss: 0.0976760311126709, Accuracy: 0.61\n",
      "Epoch 878, Loss: 0.09767174673080445, Accuracy: 0.61\n",
      "Epoch 879, Loss: 0.09766747164726257, Accuracy: 0.61\n",
      "Epoch 880, Loss: 0.09766320943832398, Accuracy: 0.61\n",
      "Epoch 881, Loss: 0.0976589548587799, Accuracy: 0.61\n",
      "Epoch 882, Loss: 0.09765471243858337, Accuracy: 0.61\n",
      "Epoch 883, Loss: 0.09765048122406006, Accuracy: 0.61\n",
      "Epoch 884, Loss: 0.09764625740051269, Accuracy: 0.61\n",
      "Epoch 885, Loss: 0.09764204668998719, Accuracy: 0.61\n",
      "Epoch 886, Loss: 0.09763784408569336, Accuracy: 0.61\n",
      "Epoch 887, Loss: 0.09763365340232849, Accuracy: 0.61\n",
      "Epoch 888, Loss: 0.09762947177886963, Accuracy: 0.61\n",
      "Epoch 889, Loss: 0.09762530136108398, Accuracy: 0.61\n",
      "Epoch 890, Loss: 0.09762113904953003, Accuracy: 0.61\n",
      "Epoch 891, Loss: 0.09761698746681213, Accuracy: 0.61\n",
      "Epoch 892, Loss: 0.09761284780502319, Accuracy: 0.61\n",
      "Epoch 893, Loss: 0.09760871696472168, Accuracy: 0.61\n",
      "Epoch 894, Loss: 0.09760459470748901, Accuracy: 0.61\n",
      "Epoch 895, Loss: 0.09760048389434814, Accuracy: 0.61\n",
      "Epoch 896, Loss: 0.09759638214111328, Accuracy: 0.61\n",
      "Epoch 897, Loss: 0.09759229016304016, Accuracy: 0.61\n",
      "Epoch 898, Loss: 0.09758820796012878, Accuracy: 0.62\n",
      "Epoch 899, Loss: 0.09758413505554199, Accuracy: 0.62\n",
      "Epoch 900, Loss: 0.09758007383346558, Accuracy: 0.62\n",
      "Epoch 901, Loss: 0.09757602000236511, Accuracy: 0.62\n",
      "Epoch 902, Loss: 0.09757197594642639, Accuracy: 0.62\n",
      "Epoch 903, Loss: 0.09756794190406799, Accuracy: 0.62\n",
      "Epoch 904, Loss: 0.09756391644477844, Accuracy: 0.62\n",
      "Epoch 905, Loss: 0.09755990386009217, Accuracy: 0.62\n",
      "Epoch 906, Loss: 0.09755589652061462, Accuracy: 0.62\n",
      "Epoch 907, Loss: 0.09755189967155456, Accuracy: 0.62\n",
      "Epoch 908, Loss: 0.09754791235923767, Accuracy: 0.62\n",
      "Epoch 909, Loss: 0.09754393362998963, Accuracy: 0.62\n",
      "Epoch 910, Loss: 0.09753996539115906, Accuracy: 0.62\n",
      "Epoch 911, Loss: 0.0975360074043274, Accuracy: 0.62\n",
      "Epoch 912, Loss: 0.09753205633163452, Accuracy: 0.62\n",
      "Epoch 913, Loss: 0.09752811455726623, Accuracy: 0.62\n",
      "Epoch 914, Loss: 0.0975241847038269, Accuracy: 0.62\n",
      "Epoch 915, Loss: 0.0975202612876892, Accuracy: 0.62\n",
      "Epoch 916, Loss: 0.09751634573936463, Accuracy: 0.62\n",
      "Epoch 917, Loss: 0.09751244425773621, Accuracy: 0.62\n",
      "Epoch 918, Loss: 0.09750854563713074, Accuracy: 0.62\n",
      "Epoch 919, Loss: 0.09750465941429139, Accuracy: 0.62\n",
      "Epoch 920, Loss: 0.09750077962875366, Accuracy: 0.62\n",
      "Epoch 921, Loss: 0.09749691104888916, Accuracy: 0.62\n",
      "Epoch 922, Loss: 0.0974930522441864, Accuracy: 0.62\n",
      "Epoch 923, Loss: 0.09748919844627381, Accuracy: 0.62\n",
      "Epoch 924, Loss: 0.09748535704612732, Accuracy: 0.62\n",
      "Epoch 925, Loss: 0.09748152279853821, Accuracy: 0.62\n",
      "Epoch 926, Loss: 0.09747769784927368, Accuracy: 0.62\n",
      "Epoch 927, Loss: 0.09747388029098511, Accuracy: 0.62\n",
      "Epoch 928, Loss: 0.09747007298469544, Accuracy: 0.62\n",
      "Epoch 929, Loss: 0.09746627187728882, Accuracy: 0.62\n",
      "Epoch 930, Loss: 0.09746248149871826, Accuracy: 0.62\n",
      "Epoch 931, Loss: 0.09745869946479797, Accuracy: 0.62\n",
      "Epoch 932, Loss: 0.09745492362976074, Accuracy: 0.62\n",
      "Epoch 933, Loss: 0.09745115876197814, Accuracy: 0.62\n",
      "Epoch 934, Loss: 0.09744740128517151, Accuracy: 0.62\n",
      "Epoch 935, Loss: 0.09744365215301513, Accuracy: 0.62\n",
      "Epoch 936, Loss: 0.09743991231918335, Accuracy: 0.62\n",
      "Epoch 937, Loss: 0.09743618083000183, Accuracy: 0.62\n",
      "Epoch 938, Loss: 0.09743245625495911, Accuracy: 0.62\n",
      "Epoch 939, Loss: 0.09742874050140381, Accuracy: 0.62\n",
      "Epoch 940, Loss: 0.09742503261566163, Accuracy: 0.62\n",
      "Epoch 941, Loss: 0.0974213330745697, Accuracy: 0.62\n",
      "Epoch 942, Loss: 0.09741764211654663, Accuracy: 0.62\n",
      "Epoch 943, Loss: 0.09741396045684815, Accuracy: 0.62\n",
      "Epoch 944, Loss: 0.09741028380393982, Accuracy: 0.62\n",
      "Epoch 945, Loss: 0.09740661764144898, Accuracy: 0.62\n",
      "Epoch 946, Loss: 0.09740295886993408, Accuracy: 0.62\n",
      "Epoch 947, Loss: 0.09739930820465088, Accuracy: 0.62\n",
      "Epoch 948, Loss: 0.09739566421508788, Accuracy: 0.62\n",
      "Epoch 949, Loss: 0.09739203190803528, Accuracy: 0.62\n",
      "Epoch 950, Loss: 0.09738840556144715, Accuracy: 0.62\n",
      "Epoch 951, Loss: 0.09738478636741638, Accuracy: 0.62\n",
      "Epoch 952, Loss: 0.09738117551803589, Accuracy: 0.62\n",
      "Epoch 953, Loss: 0.09737757134437561, Accuracy: 0.62\n",
      "Epoch 954, Loss: 0.09737397623062134, Accuracy: 0.62\n",
      "Epoch 955, Loss: 0.09737039113044739, Accuracy: 0.62\n",
      "Epoch 956, Loss: 0.09736681079864502, Accuracy: 0.62\n",
      "Epoch 957, Loss: 0.09736323833465577, Accuracy: 0.62\n",
      "Epoch 958, Loss: 0.09735967612266541, Accuracy: 0.62\n",
      "Epoch 959, Loss: 0.09735611867904663, Accuracy: 0.62\n",
      "Epoch 960, Loss: 0.09735257148742676, Accuracy: 0.62\n",
      "Epoch 961, Loss: 0.09734902954101562, Accuracy: 0.62\n",
      "Epoch 962, Loss: 0.09734549880027771, Accuracy: 0.62\n",
      "Epoch 963, Loss: 0.09734197044372558, Accuracy: 0.62\n",
      "Epoch 964, Loss: 0.09733845329284668, Accuracy: 0.62\n",
      "Epoch 965, Loss: 0.097334942817688, Accuracy: 0.62\n",
      "Epoch 966, Loss: 0.09733144044876099, Accuracy: 0.62\n",
      "Epoch 967, Loss: 0.09732794618606568, Accuracy: 0.62\n",
      "Epoch 968, Loss: 0.09732445907592774, Accuracy: 0.62\n",
      "Epoch 969, Loss: 0.09732097673416137, Accuracy: 0.62\n",
      "Epoch 970, Loss: 0.0973175060749054, Accuracy: 0.62\n",
      "Epoch 971, Loss: 0.097314040184021, Accuracy: 0.62\n",
      "Epoch 972, Loss: 0.09731058096885681, Accuracy: 0.62\n",
      "Epoch 973, Loss: 0.09730713152885437, Accuracy: 0.62\n",
      "Epoch 974, Loss: 0.09730368947982788, Accuracy: 0.62\n",
      "Epoch 975, Loss: 0.09730025434494019, Accuracy: 0.62\n",
      "Epoch 976, Loss: 0.09729682517051697, Accuracy: 0.62\n",
      "Epoch 977, Loss: 0.09729340291023254, Accuracy: 0.62\n",
      "Epoch 978, Loss: 0.09728998923301697, Accuracy: 0.62\n",
      "Epoch 979, Loss: 0.0972865846157074, Accuracy: 0.62\n",
      "Epoch 980, Loss: 0.0972831847667694, Accuracy: 0.62\n",
      "Epoch 981, Loss: 0.09727979278564453, Accuracy: 0.62\n",
      "Epoch 982, Loss: 0.09727640843391419, Accuracy: 0.62\n",
      "Epoch 983, Loss: 0.09727303123474121, Accuracy: 0.62\n",
      "Epoch 984, Loss: 0.09726965975761413, Accuracy: 0.62\n",
      "Epoch 985, Loss: 0.09726629686355591, Accuracy: 0.62\n",
      "Epoch 986, Loss: 0.09726294040679932, Accuracy: 0.62\n",
      "Epoch 987, Loss: 0.09725959205627441, Accuracy: 0.62\n",
      "Epoch 988, Loss: 0.09725625205039978, Accuracy: 0.62\n",
      "Epoch 989, Loss: 0.09725291562080383, Accuracy: 0.62\n",
      "Epoch 990, Loss: 0.09724958729743957, Accuracy: 0.62\n",
      "Epoch 991, Loss: 0.09724627041816711, Accuracy: 0.62\n",
      "Epoch 992, Loss: 0.09724295449256896, Accuracy: 0.62\n",
      "Epoch 993, Loss: 0.0972396490573883, Accuracy: 0.62\n",
      "Epoch 994, Loss: 0.09723634839057922, Accuracy: 0.62\n",
      "Epoch 995, Loss: 0.09723305487632751, Accuracy: 0.62\n",
      "Epoch 996, Loss: 0.0972297694683075, Accuracy: 0.62\n",
      "Epoch 997, Loss: 0.097226491689682, Accuracy: 0.62\n",
      "Epoch 998, Loss: 0.09722321939468384, Accuracy: 0.62\n",
      "Epoch 999, Loss: 0.09721995520591736, Accuracy: 0.62\n",
      "Epoch 1000, Loss: 0.09721669697761536, Accuracy: 0.62\n"
     ]
    }
   ],
   "source": [
    "# 使用数据训练三个mlp模型\n",
    "model_small = MLP(128, 64, 10)\n",
    "model_medium = MLP(128, 64, 10)\n",
    "model_large = MLP(128, 64, 10)\n",
    "\n",
    "# 数据准备\n",
    "x_train_small = torch.Tensor(data_small[0])\n",
    "y_train_small = torch.Tensor(data_small[1])\n",
    "label_train_small = torch.Tensor(one_hot(data_small[1], 10))\n",
    "x_val_small = torch.Tensor(data_small[2])\n",
    "y_val_small = torch.Tensor(data_small[3])\n",
    "\n",
    "x_train_medium = torch.Tensor(data_medium[0])\n",
    "y_train_medium = torch.Tensor(data_medium[1])\n",
    "label_train_medium = torch.Tensor(one_hot(data_medium[1], 10))\n",
    "x_val_medium = torch.Tensor(data_medium[2])\n",
    "y_val_medium = torch.Tensor(data_medium[3])\n",
    "\n",
    "x_train_large = torch.Tensor(data_large[0])\n",
    "y_train_large = torch.Tensor(data_large[1])\n",
    "label_train_larget = torch.Tensor(one_hot(data_large[1], 10))\n",
    "x_val_large = torch.Tensor(data_large[2])\n",
    "y_val_large = torch.Tensor(data_large[3])\n",
    "\n",
    "\n",
    "# # 模型和数据都放入GPU\n",
    "# model = model.cuda()\n",
    "# for i in range(4):\n",
    "#     data_small[i] = data_small[i].cuda()\n",
    "#     data_medium[i] = data_medium[i].cuda()\n",
    "#     data_large[i] = data_large[i].cuda()\n",
    "\n",
    "# 定义损失和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_small = optim.SGD(model_small.parameters(), lr=0.01, momentum=0.9)\n",
    "optimizer_medium = optim.SGD(model_medium.parameters(), lr=0.01, momentum=0.9)\n",
    "optimizer_large = optim.SGD(model_large.parameters(), lr=0.01, momentum=0.9)\n",
    "print(type(optimizer_large))\n",
    "\n",
    "\n",
    "def train(model:MLP, batch_size: int, epochs: int, optimizer, model_name: str, optimizer_name:str, log_path: str = \"logs/\"):\n",
    "    \"\"\"训练\n",
    "\n",
    "    Args:\n",
    "        model (MLP): _description_\n",
    "        batch_size (int): _description_\n",
    "        epochs (int): _description_\n",
    "        optimizer (_type_): _description_\n",
    "        model_name (str): 模型名称，用于log信息\n",
    "        optimizer_name (str): 优化器名称\n",
    "        log_path (str, optional): 日志位置. Defaults to \"logs/\".\n",
    "    \"\"\"\n",
    "    file_name = f\"model-{model_name}_batch_size-{batch_size}_epochs-{epochs}_optimizer-{optimizer_name}.csv\"\n",
    "    file = open(log_path + file_name, \"w\")\n",
    "    file.write(\"epoch, loss, acc\\n\")\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for i in range(0, len(x_train_small), batch_size):\n",
    "            # 获取一个 batch 的数据和标签\n",
    "            inputs = x_train_small[i:i+batch_size]\n",
    "            labels = label_train_small[i:i+batch_size]\n",
    "\n",
    "            # 清零梯度，计算损失，反向传播和更新模型参数\n",
    "            optimizer_small.zero_grad()\n",
    "            outputs = model_small(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # 统计损失值\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        # 在测试集上评估模型性能\n",
    "        with torch.no_grad():\n",
    "            outputs = model_small(x_val_small)\n",
    "            _, predicted = torch.max(outputs, dim=1)\n",
    "            accuracy = (predicted == y_val_small).sum().item() / len(y_val_small)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}, Loss: {running_loss/len(x_train_small)}, Accuracy: {accuracy}\")\n",
    "        file.write(f\"{epoch},{running_loss/len(x_train_small)},{accuracy}\\n\")\n",
    "    file.close()\n",
    "    # # 抽取一部分batch做最小批梯度下降\n",
    "\n",
    "    # random_index = np.random.randint(0, len(data_small[0]), batch_size) # 随机生成0到len(train_data)的整数，个数为batch_size\n",
    "    # pred = model(data_small[0][index])\n",
    "    # pred.backward()\n",
    "    # loss()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. small train\n",
    "train(model_small, 16, 1000, optimizer_small, \"small\", \"sgd\")\n",
    "# 2. medium train\n",
    "train(model_medium, 16, 1000, optimizer_medium, \"medium\", \"sgd\")\n",
    "# 3. large train\n",
    "train(model_large, 16, 1000, optimizer_large, \"large\", \"sgd\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 初始化\n",
    "\n",
    "w1矩阵可以用高斯进行初始化\n",
    "\n",
    "b1矩阵可以置0初始化，可以增加拟合速度\n",
    "\n",
    "## 反向传播\n",
    "\n",
    "Loss fuction: $L = (\\boldsymbol{y}, \\boldsymbol{\\\\hat{y}})$\n",
    "\n",
    "求偏导 $\\frac{\\partial L}{\\partial w_{i, j}^{(l)}}$\n",
    "\n",
    "记 $z_i^{l} = {W_i^{l}}^T x$ 是第l层的第i个节点的点积\n",
    "\n",
    "设 $\\frac{\\partial L}{\\partial z_i^{l}}$ 为 $\\delta_i^{l}$，表示L对第l层第i个节点的点积的偏导\n",
    "\n",
    "由此可以表示 $\\frac{\\partial L}{\\partial w_{i, j}^{(l)}} = \\delta_i^{l} a_j^{l-1}$ , $a_j^{l-1}$ 就是上一层节点的激活输出\n",
    "\n",
    "现在只要能知道 $\\delta_i$ 就可以求出偏导\n",
    "\n",
    "### 如何求 $\\delta_i^{l}$\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\delta_i^{l} \\equiv \\frac{\\partial L}{\\partial z_j^{l}} = L'(a_j^l) \\sigma' (z_i^l) \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "则损失值可以表示为\n",
    "\n",
    "$$\n",
    "L = \\frac{1}{2} \\sum_j (y_j - a_j)^2 \n",
    "$$\n",
    "\n",
    "四个公式\n",
    "\n",
    "$$\n",
    "\\\\begin{aligned}\n",
    "\\end{aligned}\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ipynb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
